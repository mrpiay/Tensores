{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensores Matemáticos: Introducción y Aplicaciones en Computación\n",
    "\n",
    "> *De los escalares a los qubits entrelazados — una guía interactiva con teoría y código Python.*\n",
    ">\n",
    "> *Cada sección incluye la explicación teórica seguida de código ejecutable para experimentar.*\n",
    ">\n",
    "> **Autor:** Mr. Piay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de contenido\n",
    "\n",
    "- **Parte 1 — Fundamentos matemáticos**\n",
    "\n",
    "  1. [Partamos de lo conocido: arrays de números](#1-partamos-de-lo-conocido-arrays-de-números)\n",
    "  2. [La diferencia clave: cambiar de perspectiva](#2-la-diferencia-clave-cambiar-de-perspectiva)\n",
    "  3. [Entonces, ¿qué es un tensor?](#3-entonces-qué-es-un-tensor)\n",
    "  4. [¿Todo array es un tensor?](#4-todo-array-es-un-tensor)\n",
    "  5. [El orden del tensor: niveles de complejidad](#5-el-orden-del-tensor-niveles-de-complejidad)\n",
    "  6. [Transformación de componentes](#6-transformación-de-componentes)\n",
    "  7. [Invariantes: lo que no cambia](#7-invariantes-lo-que-no-cambia)\n",
    "\n",
    "- **Parte 2 — Tensores en Machine Learning**\n",
    "\n",
    "  8. [Tensores en ML: arrays con significado](#8-tensores-en-ml-arrays-con-significado)\n",
    "  9. [Jerarquía de datos: de escalares a tensores 4D](#9-jerarquía-de-datos-de-escalares-a-tensores-4d)\n",
    "  10. [Operaciones tensoriales en Python](#10-operaciones-tensoriales-en-python)\n",
    "  11. [Ejemplo práctico: red neuronal simple (MNIST)](#11-ejemplo-práctico-red-neuronal-simple-mnist)\n",
    "  12. [Procesando lotes (batches)](#12-procesando-lotes-batches)\n",
    "  13. [Frameworks modernos: PyTorch](#13-frameworks-modernos-pytorch)\n",
    "\n",
    "- **Parte 3 — Tensores en Computación Cuántica**\n",
    "\n",
    "  14. [El mundo cuántico: superposición y entrelazamiento](#14-el-mundo-cuántico-superposición-y-entrelazamiento)\n",
    "  15. [El estado de un qubit: un vector complejo](#15-el-estado-de-un-qubit-un-vector-complejo)\n",
    "  16. [Puertas cuánticas: matrices que transforman qubits](#16-puertas-cuánticas-matrices-que-transforman-qubits)\n",
    "  17. [Múltiples qubits: el producto tensorial](#17-múltiples-qubits-el-producto-tensorial)\n",
    "  18. [Entrelazamiento cuántico](#18-entrelazamiento-cuántico)\n",
    "  19. [Puertas en sistemas multi-qubit](#19-puertas-en-sistemas-multi-qubit)\n",
    "  20. [Ejemplo: algoritmo de Deutsch-Jozsa](#20-ejemplo-algoritmo-de-deutsch-jozsa)\n",
    "\n",
    "- **Cierre**\n",
    "\n",
    "  21. [Mapa comparativo: tensores en tres mundos](#21-mapa-comparativo-tensores-en-tres-mundos)\n",
    "  22. [Conclusión](#22-conclusión)\n",
    "  23. [Glosario rápido](#23-glosario-rápido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisitos\n",
    "\n",
    "Ejecuta las siguientes celdas para instalar dependencias e importar las bibliotecas necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuración de visualización\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PARTE 1 — Fundamentos Matemáticos**\n",
    "\n",
    "*¿Qué es realmente un tensor y por qué importa?*\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Partamos de lo conocido: arrays de números**\n",
    "\n",
    "En programación y matemáticas trabajamos constantemente con colecciones de números organizados en estructuras. A estas estructuras las llamamos *arrays*.\n",
    "\n",
    "**Ejemplo A — Temperaturas de una semana:** [20, 22, 19, 21, 23, 20, 18] °C. Siete números, uno por cada día. Un array simple.\n",
    "\n",
    "**Ejemplo B — Velocidad del viento:** [5, 3] km/h (componente Este, componente Norte). También es un array: dos números organizados en una estructura.\n",
    "\n",
    "Pero aunque ambos son arrays, **no representan lo mismo**. La diferencia se revela cuando cambiamos nuestra forma de observar.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo A: Temperaturas de una semana (array simple)\n",
    "\n",
    "temperaturas = np.array([20, 22, 19, 21, 23, 20, 18])\n",
    "dias = ['Lun', 'Mar', 'Mié', 'Jue', 'Vie', 'Sáb', 'Dom']\n",
    "\n",
    "print(\"Temperaturas de la semana (°C):\")\n",
    "print(f\"  Array: {temperaturas}\")\n",
    "print(f\"  Forma (shape): {temperaturas.shape}\")\n",
    "print(f\"  Dimensiones: {temperaturas.ndim}\")\n",
    "print(f\"  Promedio: {temperaturas.mean():.1f} °C\")\n",
    "print(f\"  Máxima: {temperaturas.max()} °C ({dias[temperaturas.argmax()]})\")\n",
    "print(f\"  Mínima: {temperaturas.min()} °C ({dias[temperaturas.argmin()]})\")\n",
    "print()\n",
    "print(\"Esto es un array simple: 7 mediciones independientes.\")\n",
    "print(\"NO es un tensor — no tiene significado geométrico ni reglas de transformación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo B: Velocidad del viento (vector con significado geométrico)\n",
    "\n",
    "velocidad = np.array([5, 3])  # km/h (Este, Norte)\n",
    "\n",
    "magnitud = np.linalg.norm(velocidad)\n",
    "angulo = np.degrees(np.arctan2(velocidad[1], velocidad[0]))\n",
    "\n",
    "print(\"Velocidad del viento:\")\n",
    "print(f\"  Componentes: Este={velocidad[0]}, Norte={velocidad[1]} km/h\")\n",
    "print(f\"  Forma (shape): {velocidad.shape}\")\n",
    "print(f\"  Magnitud: {magnitud:.2f} km/h\")\n",
    "print(f\"  Dirección: {angulo:.1f}° desde el Este\")\n",
    "print()\n",
    "print(\"Esto SÍ es un tensor (de orden 1 = vector):\")\n",
    "print(\"  - Tiene significado geométrico (magnitud + dirección)\")\n",
    "print(\"  - Sus componentes cambian al rotar los ejes\")\n",
    "print(\"  - La magnitud permanece invariante\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el vector velocidad del viento\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "# Dibujar el vector\n",
    "ax.quiver(0, 0, 5, 3, angles='xy', scale_units='xy', scale=1,\n",
    "          color='royalblue', width=0.02, label='Velocidad [5, 3]')\n",
    "\n",
    "# Anotar componentes\n",
    "ax.annotate('', xy=(5, 0), xytext=(0, 0),\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "ax.annotate('', xy=(5, 3), xytext=(5, 0),\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "ax.text(2.5, -0.5, 'Este = 5', ha='center', color='gray', fontsize=10)\n",
    "ax.text(5.5, 1.5, 'Norte = 3', ha='left', color='gray', fontsize=10)\n",
    "ax.text(1.5, 2.2, f'|v| = {np.linalg.norm([5,3]):.2f}', fontsize=12,\n",
    "        color='royalblue', fontweight='bold')\n",
    "\n",
    "ax.set_xlim(-1, 7)\n",
    "ax.set_ylim(-1, 5)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlabel('Este (km/h)')\n",
    "ax.set_ylabel('Norte (km/h)')\n",
    "ax.set_title('Vector velocidad del viento')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. La diferencia clave: cambiar de perspectiva**\n",
    "\n",
    "### Temperaturas\n",
    "\n",
    "Si pasamos de Celsius a Fahrenheit, los números cambian por una simple conversión de unidades: 20 °C → 68 °F. No hay direcciones, orientación ni geometría involucrada. Es un cambio puramente numérico.\n",
    "\n",
    "### Velocidad del viento\n",
    "\n",
    "Ahora imaginemos que rotamos nuestros ejes de referencia 90° en sentido antihorario. El viento sigue soplando exactamente igual, pero nuestra **descripción numérica cambia por completo**: de [5, 3] en ejes originales a [3, −5] en los nuevos ejes.\n",
    "\n",
    "Observa lo que ocurre:\n",
    "\n",
    "- El **fenómeno físico** (el viento) no cambia.\n",
    "- La **descripción numérica** sí cambia.\n",
    "- Los números cambian según una **regla matemática precisa** (la matriz de rotación).\n",
    "\n",
    "Esto revela algo profundo: la velocidad del viento no es solo un par de números. Es un **objeto geométrico** que existe independientemente de cómo lo describamos.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Temperaturas: conversión de unidades (NO es un cambio de coordenadas)\n",
    "temp_celsius = 20\n",
    "temp_fahrenheit = temp_celsius * 9/5 + 32\n",
    "\n",
    "print(\"=== TEMPERATURAS ===\")\n",
    "print(f\"{temp_celsius}°C  →  {temp_fahrenheit}°F\")\n",
    "print(\"Solo cambia la escala numérica. No hay geometría involucrada.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Velocidad del viento: rotación de ejes (cambio de coordenadas real)\n",
    "def matriz_rotacion(angulo_grados):\n",
    "    \"\"\"Crea una matriz de rotación 2D.\"\"\"\n",
    "    theta = np.radians(angulo_grados)\n",
    "    return np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                     [np.sin(theta),  np.cos(theta)]])\n",
    "\n",
    "v = np.array([5, 3])  # Velocidad original\n",
    "angulo = 90            # Rotar ejes 90° antihorario\n",
    "\n",
    "R = matriz_rotacion(angulo)\n",
    "v_rotado = R @ v\n",
    "\n",
    "print(\"=== VELOCIDAD DEL VIENTO ===\")\n",
    "print(f\"Ejes originales:   v = {v}\")\n",
    "print(f\"Ejes rotados {angulo}°:  v = {v_rotado}\")\n",
    "print()\n",
    "print(f\"Magnitud original:  |v| = {np.linalg.norm(v):.4f} km/h\")\n",
    "print(f\"Magnitud tras rotar: |v| = {np.linalg.norm(v_rotado):.4f} km/h\")\n",
    "print()\n",
    "print(\"Los números cambiaron, pero la magnitud es la misma.\")\n",
    "print(\"El viento no cambió; solo cambió nuestra descripción.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la rotación\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for ax, vec, titulo, ejes in [\n",
    "    (ax1, v, 'Ejes originales', ('Este', 'Norte')),\n",
    "    (ax2, v_rotado, 'Ejes rotados 90°', (\"Este'\", \"Norte'\"))\n",
    "]:\n",
    "    ax.quiver(0, 0, vec[0], vec[1], angles='xy', scale_units='xy', scale=1,\n",
    "              color='steelblue', width=0.02)\n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(-6, 6)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(y=0, color='k', linewidth=0.5)\n",
    "    ax.axvline(x=0, color='k', linewidth=0.5)\n",
    "    ax.set_xlabel(ejes[0])\n",
    "    ax.set_ylabel(ejes[1])\n",
    "    ax.set_title(f'{titulo}\\nv = [{vec[0]:.1f}, {vec[1]:.1f}]')\n",
    "    ax.annotate(f'|v| = {np.linalg.norm(vec):.2f}',\n",
    "                xy=(vec[0]/2, vec[1]/2),\n",
    "                xytext=(vec[0]/2 + 1, vec[1]/2 + 1),\n",
    "                fontsize=10, color='red',\n",
    "                arrowprops=dict(arrowstyle='->', color='red', alpha=0.5))\n",
    "\n",
    "fig.suptitle('Mismo vector, distinta descripción', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Entonces, ¿qué es un tensor?**\n",
    "\n",
    "Un **tensor** es un objeto matemático abstracto que cumple estas propiedades:\n",
    "\n",
    "1. **Representa una cantidad con estructura geométrica o física.**\n",
    "2. **Existe independientemente del sistema de coordenadas.**\n",
    "3. **Se expresa mediante números (componentes) cuando elegimos una base.**\n",
    "4. **Sus componentes cambian según reglas matemáticas precisas al cambiar de referencia.**\n",
    "5. **La entidad que describe permanece invariante.**\n",
    "\n",
    "### La distinción esencial\n",
    "\n",
    "> **TENSOR ≠ COMPONENTES**\n",
    ">\n",
    "> **Tensor** → la entidad geométrica o física.\n",
    "> **Componentes** → los números que lo representan en un sistema de coordenadas particular.\n",
    "\n",
    "**Analogía:** Una mesa no cambia si caminas alrededor de ella. Lo que cambia es tu *perspectiva* — qué lado ves primero, qué ángulo percibes. La mesa (el tensor) sigue siendo la misma; tu descripción (las componentes) es lo que varía.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demostración: el mismo vector descrito en muchos sistemas de referencia\n",
    "\n",
    "v_original = np.array([5, 3])  # El tensor (vector) original\n",
    "\n",
    "print(\"El MISMO vector visto desde distintos sistemas de referencia:\\n\")\n",
    "print(f\"{'Ángulo':>8}  {'Componentes':>20}  {'Magnitud':>10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for angulo in range(0, 360, 45):\n",
    "    R = matriz_rotacion(angulo)\n",
    "    v_nuevo = R @ v_original\n",
    "    mag = np.linalg.norm(v_nuevo)\n",
    "    print(f\"{angulo:>7}°  [{v_nuevo[0]:>8.3f}, {v_nuevo[1]:>8.3f}]  {mag:>10.4f}\")\n",
    "\n",
    "print(\"\\nLas componentes cambian. La magnitud (invariante) no.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. ¿Todo array es un tensor?**\n",
    "\n",
    "**No.**\n",
    "\n",
    "Volvamos a nuestros dos ejemplos iniciales:\n",
    "\n",
    "| Propiedad | Temperaturas [20, 22, 19, ...] | Velocidad [5, 3] |\n",
    "|---|---|---|\n",
    "| ¿Es un array? | Sí | Sí |\n",
    "| ¿Tiene significado geométrico? | No (son mediciones independientes) | Sí (magnitud + dirección) |\n",
    "| ¿Sigue reglas de transformación espacial? | No | Sí (rotación de ejes) |\n",
    "| ¿Es un tensor? | No (cada temperatura individual es un escalar) | Sí (es un vector = tensor de orden 1) |\n",
    "\n",
    "Un tensor se caracteriza por:\n",
    "\n",
    "1. **Significado geométrico o físico** — describe algo real que existe en el espacio.\n",
    "2. **Leyes de transformación** — sus componentes cambian de forma predecible al cambiar coordenadas.\n",
    "3. **Relación entre direcciones** — conecta una o más direcciones del espacio.\n",
    "\n",
    "Un array común puede ser útil computacionalmente, pero eso no lo convierte automáticamente en un tensor.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array que NO es un tensor: lista de temperaturas\n",
    "temperaturas = np.array([20, 22, 19, 21, 23, 20, 18])\n",
    "\n",
    "# Array que SÍ es un tensor: vector velocidad\n",
    "velocidad = np.array([5, 3])\n",
    "\n",
    "print(\"=== COMPARACIÓN ===\")\n",
    "print()\n",
    "print(f\"Temperaturas: {temperaturas}\")\n",
    "print(f\"  ¿Es un array?                           Sí\")\n",
    "print(f\"  ¿Tiene significado geométrico?          No (son mediciones independientes)\")\n",
    "print(f\"  ¿Sigue reglas de transformación?        No\")\n",
    "print(f\"  ¿Es un tensor?                          No\")\n",
    "print()\n",
    "print(f\"Velocidad: {velocidad}\")\n",
    "print(f\"  ¿Es un array?                           Sí\")\n",
    "print(f\"  ¿Tiene significado geométrico?          Sí (magnitud + dirección)\")\n",
    "print(f\"  ¿Sigue reglas de transformación?        Sí (rotación de ejes)\")\n",
    "print(f\"  ¿Es un tensor?                          Sí (vector = tensor de orden 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. El orden del tensor: niveles de complejidad**\n",
    "\n",
    "El **orden** (también llamado *rango*) de un tensor indica cuántos índices se necesitan para especificar cada componente, o equivalentemente, cuántas direcciones están involucradas.\n",
    "\n",
    "### Orden 0 — Escalar\n",
    "\n",
    "Un solo número. No depende de direcciones. Ejemplos: temperatura (20 °C), masa (5 kg), tiempo (3.2 s).\n",
    "\n",
    "> Un escalar es el mismo número sin importar cómo orientes tus ejes.\n",
    "\n",
    "### Orden 1 — Vector\n",
    "\n",
    "Una cantidad con magnitud y dirección. Necesita **un índice** para recorrer sus componentes. Ejemplo: velocidad en 3D, v = (vₓ, vᵧ, v_z).\n",
    "\n",
    "> En un espacio de *n* dimensiones, un vector tiene *n* componentes.\n",
    "\n",
    "### Orden 2 — Tensor de segundo orden (puede representarse como una matriz)\n",
    "\n",
    "Relaciona **dos direcciones simultáneamente**. Necesita **dos índices** (fila y columna). Un ejemplo clásico es el **tensor de esfuerzos** en 3D: una matriz 3×3 con 9 componentes, donde cada componente σ_ij describe la fuerza en la dirección *j* que actúa sobre una superficie perpendicular a la dirección *i*.\n",
    "\n",
    "### Orden 3 y superiores\n",
    "\n",
    "Describen relaciones entre tres o más direcciones. Aparecen en fenómenos como la piezoelectricidad (orden 3), la elasticidad general (orden 4), relatividad general y física cuántica.\n",
    "\n",
    "| Orden | Nombre | Componentes en espacio 3D | Fórmula |\n",
    "|-------|--------|---------------------------|---------|\n",
    "| 0 | Escalar | 1 | 3⁰ |\n",
    "| 1 | Vector | 3 | 3¹ |\n",
    "| 2 | Matriz | 9 | 3² |\n",
    "| 3 | Cubo | 27 | 3³ |\n",
    "| 4 | Hipercubo | 81 | 3⁴ |\n",
    "\n",
    "> Mientras mayor el orden, más complejas las relaciones que el tensor puede describir.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ORDEN 0: ESCALAR ===\n",
    "# Un solo número. No depende de direcciones.\n",
    "\n",
    "temperatura = 20.0  # °C\n",
    "masa = 5.0          # kg\n",
    "tiempo = 3.2        # s\n",
    "\n",
    "# En NumPy: un array 0-dimensional\n",
    "escalar = np.array(42.0)\n",
    "\n",
    "print(\"=== ORDEN 0: ESCALAR ===\")\n",
    "print(f\"Temperatura: {temperatura}°C\")\n",
    "print(f\"Como array NumPy: {escalar}\")\n",
    "print(f\"Forma (shape): {escalar.shape}  →  0 índices\")\n",
    "print(f\"Dimensión (ndim): {escalar.ndim}\")\n",
    "print(f\"Número de componentes: {escalar.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ORDEN 1: VECTOR ===\n",
    "# Magnitud y dirección. Un índice para recorrer componentes.\n",
    "\n",
    "velocidad_3d = np.array([3, -1, 4])  # m/s en (x, y, z)\n",
    "\n",
    "print(\"=== ORDEN 1: VECTOR ===\")\n",
    "print(f\"Velocidad 3D: {velocidad_3d} m/s\")\n",
    "print(f\"Forma (shape): {velocidad_3d.shape}  →  1 índice\")\n",
    "print(f\"Dimensión (ndim): {velocidad_3d.ndim}\")\n",
    "print(f\"Número de componentes: {velocidad_3d.size}\")\n",
    "print(f\"Acceso por índice: v[0]={velocidad_3d[0]}, v[1]={velocidad_3d[1]}, v[2]={velocidad_3d[2]}\")\n",
    "print(f\"Magnitud: |v| = {np.linalg.norm(velocidad_3d):.4f} m/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ORDEN 2: TENSOR DE SEGUNDO ORDEN (MATRIZ) ===\n",
    "# Relaciona dos direcciones. Dos índices (fila, columna).\n",
    "\n",
    "# Tensor de esfuerzos: describe fuerzas internas en un material\n",
    "sigma = np.array([\n",
    "    [100,  20,   0],   # Fuerzas en superficie perpendicular a x\n",
    "    [ 20,  50,   0],   # Fuerzas en superficie perpendicular a y\n",
    "    [  0,   0,  30]    # Fuerzas en superficie perpendicular a z\n",
    "])  # Unidades: MPa\n",
    "\n",
    "print(\"=== ORDEN 2: TENSOR DE ESFUERZOS ===\")\n",
    "print(f\"Forma (shape): {sigma.shape}  →  2 índices\")\n",
    "print(f\"Dimensión (ndim): {sigma.ndim}\")\n",
    "print(f\"Número de componentes: {sigma.size}\")\n",
    "print(f\"\\nTensor σ (MPa):\")\n",
    "print(sigma)\n",
    "print(f\"\\nσ[0,1] = {sigma[0,1]} MPa  →  fuerza en dirección y sobre superficie ⊥ a x\")\n",
    "print(f\"σ[1,0] = {sigma[1,0]} MPa  →  fuerza en dirección x sobre superficie ⊥ a y\")\n",
    "print(\"(La simetría σ[i,j] = σ[j,i] es una propiedad física del tensor de esfuerzos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ORDENES SUPERIORES ===\n",
    "# Cantidad de componentes en espacio 3D: 3^orden\n",
    "\n",
    "print(\"Componentes de un tensor en espacio 3D:\\n\")\n",
    "print(f\"{'Orden':>6}  {'Nombre':>15}  {'Componentes':>12}  {'Fórmula':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "nombres = ['Escalar', 'Vector', 'Matriz', 'Cubo', 'Hipercubo']\n",
    "for orden in range(5):\n",
    "    n_componentes = 3 ** orden\n",
    "    print(f\"{orden:>6}  {nombres[orden]:>15}  {n_componentes:>12}  {'3^' + str(orden):>10}\")\n",
    "\n",
    "# Crear ejemplos reales\n",
    "print(\"\\nEjemplos en NumPy:\")\n",
    "for orden, nombre in enumerate(nombres[:4]):\n",
    "    t = np.zeros([3] * orden) if orden > 0 else np.array(0.0)\n",
    "    print(f\"  Orden {orden} ({nombre}): shape = {t.shape}, ndim = {t.ndim}, size = {t.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Transformación de componentes**\n",
    "\n",
    "Lo que distingue a un tensor de un simple array es **cómo cambian sus números al rotar los ejes**.\n",
    "\n",
    "### Ejemplo: vector en 2D\n",
    "\n",
    "Consideremos un vector velocidad **v** = [3, 4] km/h en ejes (Este, Norte). Si rotamos los ejes 90° en sentido antihorario, las nuevas componentes se obtienen mediante la **matriz de rotación**:\n",
    "\n",
    "$$\n",
    "\\mathbf{v'} = R \\cdot \\mathbf{v}\n",
    "$$\n",
    "\n",
    "Los números cambian de [3, 4] a [4, −3], pero la **magnitud** permanece:\n",
    "\n",
    "$$\n",
    "|\\mathbf{v}| = \\sqrt{3^2 + 4^2} = \\sqrt{4^2 + (-3)^2} = 5 \\text{ km/h}\n",
    "$$\n",
    "\n",
    "El vector (tensor) es el mismo; las componentes se adaptan al nuevo sistema de referencia.\n",
    "\n",
    "> Esta regla de transformación es lo que define matemáticamente a un tensor.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de un VECTOR (tensor de orden 1)\n",
    "\n",
    "v = np.array([3, 4])  # Vector original\n",
    "angulo = 90  # grados\n",
    "\n",
    "R = matriz_rotacion(angulo)\n",
    "v_nuevo = R @ v\n",
    "\n",
    "print(\"=== Transformación de un vector ===\")\n",
    "print(f\"\\nMatriz de rotación ({angulo}°):\")\n",
    "print(R)\n",
    "print(f\"\\nVector original:       v  = {v}\")\n",
    "print(f\"Vector transformado:   v' = {v_nuevo}\")\n",
    "print(f\"\\nMagnitud original:  |v|  = {np.linalg.norm(v):.4f}\")\n",
    "print(f\"Magnitud nueva:     |v'| = {np.linalg.norm(v_nuevo):.4f}\")\n",
    "print(\"\\nRegla: v' = R · v  (multiplicación matriz-vector)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de una MATRIZ (tensor de orden 2)\n",
    "# Regla: σ' = R · σ · R^T\n",
    "\n",
    "sigma = np.array([[100, 20],\n",
    "                  [ 20, 50]])  # Tensor de esfuerzos 2D\n",
    "\n",
    "angulo = 45  # grados\n",
    "R = matriz_rotacion(angulo)\n",
    "\n",
    "# Transformación de tensor de orden 2\n",
    "sigma_nuevo = R @ sigma @ R.T\n",
    "\n",
    "print(\"=== Transformación de un tensor de orden 2 ===\")\n",
    "print(f\"\\nTensor original σ:\")\n",
    "print(sigma)\n",
    "print(f\"\\nTensor tras rotar {angulo}° (σ' = R·σ·Rᵀ):\")\n",
    "print(sigma_nuevo)\n",
    "print(f\"\\nTraza original:  {np.trace(sigma):.4f}\")\n",
    "print(f\"Traza nueva:     {np.trace(sigma_nuevo):.4f}\")\n",
    "print(f\"\\nDet original:    {np.linalg.det(sigma):.4f}\")\n",
    "print(f\"Det nuevo:       {np.linalg.det(sigma_nuevo):.4f}\")\n",
    "print(\"\\nTraza y determinante son INVARIANTES: no cambian al rotar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Invariantes: lo que no cambia**\n",
    "\n",
    "Si las componentes de un tensor cambian con el sistema de referencia, ¿hay algo que permanezca constante? Sí: los **invariantes**.\n",
    "\n",
    "### Para un vector (orden 1)\n",
    "\n",
    "La **magnitud** es invariante: $|\\mathbf{v}| = \\sqrt{v_x^2 + v_y^2 + v_z^2}$ es constante en cualquier sistema de ejes.\n",
    "\n",
    "### Para una matriz/tensor de orden 2\n",
    "\n",
    "La **traza** (suma de la diagonal) es invariante. Por ejemplo, para un tensor de esfuerzos con componentes [[100, 20], [20, 50]], la traza es 150 y no cambia al rotar los ejes. El **determinante** (100×50 − 20×20 = 4600) tampoco cambia.\n",
    "\n",
    "> Los invariantes son las \"huellas dactilares\" de un tensor: permiten identificarlo\n",
    "> sin importar desde qué perspectiva lo observes.\n",
    "\n",
    "### Idea central de la Parte 1\n",
    "\n",
    "> **Un tensor no se define por ser una tabla de números, sino por CÓMO sus componentes cambian cuando cambia el sistema de referencia.**\n",
    ">\n",
    "> Los números pueden variar. La entidad que describen permanece.\n",
    "\n",
    "Por eso los tensores son el lenguaje natural de la física, la geometría moderna y muchas áreas de la computación.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar invariantes para múltiples rotaciones\n",
    "\n",
    "sigma = np.array([[100, 20],\n",
    "                  [ 20, 50]])\n",
    "\n",
    "print(\"Tensor de esfuerzos σ visto desde distintos ángulos:\\n\")\n",
    "print(f\"{'Ángulo':>7}  {'σ[0,0]':>8}  {'σ[0,1]':>8}  {'σ[1,0]':>8}  {'σ[1,1]':>8}  │  {'Traza':>8}  {'Det':>10}\")\n",
    "print(\"-\" * 78)\n",
    "\n",
    "for angulo in range(0, 181, 30):\n",
    "    R = matriz_rotacion(angulo)\n",
    "    s = R @ sigma @ R.T\n",
    "    print(f\"{angulo:>6}°  {s[0,0]:>8.2f}  {s[0,1]:>8.2f}  {s[1,0]:>8.2f}  {s[1,1]:>8.2f}  │  {np.trace(s):>8.2f}  {np.linalg.det(s):>10.2f}\")\n",
    "\n",
    "print(\"\\nLas componentes cambian (columnas izquierdas).\")\n",
    "print(\"Los invariantes permanecen constantes (columnas derechas).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar cómo cambian las componentes pero no los invariantes\n",
    "\n",
    "angulos = np.arange(0, 361, 1)\n",
    "componentes_00 = []\n",
    "componentes_01 = []\n",
    "trazas = []\n",
    "determinantes = []\n",
    "\n",
    "for ang in angulos:\n",
    "    R = matriz_rotacion(ang)\n",
    "    s = R @ sigma @ R.T\n",
    "    componentes_00.append(s[0, 0])\n",
    "    componentes_01.append(s[0, 1])\n",
    "    trazas.append(np.trace(s))\n",
    "    determinantes.append(np.linalg.det(s))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 7), sharex=True)\n",
    "\n",
    "ax1.plot(angulos, componentes_00, label='σ[0,0]', linewidth=2)\n",
    "ax1.plot(angulos, componentes_01, label='σ[0,1]', linewidth=2)\n",
    "ax1.set_ylabel('Valor (MPa)')\n",
    "ax1.set_title('Componentes (CAMBIAN con la rotación)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(angulos, trazas, label='Traza', linewidth=2, color='green')\n",
    "ax2.plot(angulos, determinantes, label='Determinante', linewidth=2, color='red')\n",
    "ax2.set_ylabel('Valor')\n",
    "ax2.set_xlabel('Ángulo de rotación (°)')\n",
    "ax2.set_title('Invariantes (NO CAMBIAN con la rotación)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PARTE 2 — Tensores en Machine Learning**\n",
    "\n",
    "*Arrays multidimensionales que impulsan la inteligencia artificial.*\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Tensores en ML: arrays con significado**\n",
    "\n",
    "En *machine learning*, el término **tensor** se utiliza de manera más flexible que en física o geometría. Aquí, un tensor suele referirse simplemente a un **array multidimensional de números**.\n",
    "\n",
    "> **Nota importante:** Los \"tensores\" de ML no siempre son tensores matemáticos en sentido estricto: no necesariamente siguen leyes de transformación geométrica. Sin embargo, comparten la misma estructura de datos multidimensional.\n",
    ">\n",
    "> - En física → tensor = objeto geométrico invariante\n",
    "> - En ML → tensor = contenedor multidimensional optimizado\n",
    "\n",
    "### ¿Por qué se usa la palabra \"tensor\" en ML?\n",
    "\n",
    "Porque los datos que procesan las redes neuronales poseen de forma natural múltiples dimensiones:\n",
    "\n",
    "| Tipo de dato | Dimensiones |\n",
    "|---|---|\n",
    "| Imagen a color | alto × ancho × canales de color |\n",
    "| Video | tiempo × alto × ancho × canales |\n",
    "| Dataset tabular | muestras × características |\n",
    "| Texto (embeddings) | secuencia × dimensión del embedding |\n",
    "\n",
    "Frameworks como **TensorFlow** y **PyTorch** emplean tensores porque permiten almacenar y manipular estas estructuras de forma eficiente, especialmente en GPUs diseñadas para operaciones masivas en paralelo.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensores en ML: arrays con significado\n",
    "# Comparación: un array común vs un \"tensor\" en ML\n",
    "\n",
    "# Array simple: lista de compras (sin significado geométrico ni estructura ML)\n",
    "lista_compras = [3, 1, 2, 5]  # cantidades de productos\n",
    "print(\"Array simple (lista de compras):\", lista_compras)\n",
    "print(\"  → Solo números sueltos, sin estructura espacial\\n\")\n",
    "\n",
    "# \"Tensor\" en ML: los datos SIEMPRE tienen dimensiones con significado\n",
    "import numpy as np\n",
    "\n",
    "# Imagen en escala de grises: alto × ancho\n",
    "imagen_gris = np.random.rand(28, 28)\n",
    "print(f\"Imagen gris:  shape = {imagen_gris.shape}  → (alto, ancho)\")\n",
    "\n",
    "# Imagen a color: alto × ancho × canales\n",
    "imagen_color = np.random.rand(224, 224, 3)\n",
    "print(f\"Imagen color: shape = {imagen_color.shape} → (alto, ancho, RGB)\")\n",
    "\n",
    "# Dataset tabular: muestras × características\n",
    "dataset = np.random.rand(100, 5)\n",
    "print(f\"Dataset:      shape = {dataset.shape}    → (muestras, características)\")\n",
    "\n",
    "# Embedding de texto: secuencia × dimensión\n",
    "texto = np.random.rand(50, 300)\n",
    "print(f\"Embedding:    shape = {texto.shape}     → (palabras, dimensión)\")\n",
    "\n",
    "# Lote de imágenes: batch × alto × ancho × canales\n",
    "batch = np.random.rand(32, 224, 224, 3)\n",
    "print(f\"Batch imgs:   shape = {batch.shape} → (batch, alto, ancho, RGB)\")\n",
    "\n",
    "print(\"\\n→ En ML cada dimensión tiene un SIGNIFICADO específico.\")\n",
    "print(\"  Eso es lo que distingue un tensor de ML de un array cualquiera.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Jerarquía de datos: de escalares a tensores 4D**\n",
    "\n",
    "### Escalar — Orden 0\n",
    "\n",
    "Un único número. Representa métricas o hiperparámetros: la pérdida del modelo (0.345), la precisión (0.92) o la tasa de aprendizaje (0.001).\n",
    "\n",
    "### Vector — Orden 1\n",
    "\n",
    "Una lista de números. Representa características de una persona [edad, altura, peso], probabilidades de un clasificador [0.1, 0.7, 0.2] o embeddings de palabras (vectores de 100–300 dimensiones).\n",
    "\n",
    "### Matriz — Orden 2\n",
    "\n",
    "Una tabla bidimensional. Representa imágenes en escala de grises (28×28 píxeles), datasets tabulares (100 muestras × 5 características) o pesos de una capa neuronal (784 entradas × 128 neuronas).\n",
    "\n",
    "### Tensor 3D — Orden 3\n",
    "\n",
    "Un \"cubo\" de números. Representa imágenes a color (224 × 224 × 3 canales RGB) o secuencias de texto (50 palabras × 300 dimensiones de embedding).\n",
    "\n",
    "### Tensor 4D — Orden 4\n",
    "\n",
    "Un \"hipercubo\". Representa **lotes (batches)** de datos para procesamiento en paralelo: por ejemplo, 32 imágenes RGB de 224×224 forman un tensor de dimensiones 32 × 224 × 224 × 3.\n",
    "\n",
    "> **¿Por qué usar lotes?** Porque procesar múltiples ejemplos simultáneamente\n",
    "> permite paralelización en GPU, acelerando enormemente el entrenamiento.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ESCALAR (orden 0) ===\n",
    "loss = np.float64(0.345)\n",
    "accuracy = np.float64(0.92)\n",
    "learning_rate = np.float64(0.001)\n",
    "\n",
    "print(\"=== ESCALAR (orden 0) ===\")\n",
    "print(f\"Pérdida:             {loss}\")\n",
    "print(f\"Precisión:           {accuracy}\")\n",
    "print(f\"Tasa de aprendizaje: {learning_rate}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VECTOR (orden 1) ===\n",
    "caracteristicas = np.array([25, 1.75, 70])              # edad, altura, peso\n",
    "probabilidades = np.array([0.1, 0.7, 0.2])              # clasificador de 3 clases\n",
    "embedding = np.random.randn(300)                        # embedding de una palabra\n",
    "\n",
    "print(\"=== VECTOR (orden 1) ===\")\n",
    "print(f\"Características: {caracteristicas}  →  shape: {caracteristicas.shape}\")\n",
    "print(f\"Probabilidades:  {probabilidades}  →  shape: {probabilidades.shape}\")\n",
    "print(f\"Embedding:       [{embedding[0]:.3f}, {embedding[1]:.3f}, ..., {embedding[-1]:.3f}]  →  shape: {embedding.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MATRIZ (orden 2) ===\n",
    "imagen_gris = np.random.rand(28, 28)        # Imagen MNIST\n",
    "dataset = np.random.rand(100, 5)            # 100 muestras, 5 características\n",
    "pesos_capa = np.random.randn(784, 128)      # Pesos de una capa neuronal\n",
    "\n",
    "print(\"=== MATRIZ (orden 2) ===\")\n",
    "print(f\"Imagen 28×28:        shape = {imagen_gris.shape}   →  ndim = {imagen_gris.ndim}\")\n",
    "print(f\"Dataset 100×5:       shape = {dataset.shape}  →  ndim = {dataset.ndim}\")\n",
    "print(f\"Pesos 784×128:       shape = {pesos_capa.shape} →  ndim = {pesos_capa.ndim}\")\n",
    "print()\n",
    "\n",
    "# Visualizar la imagen\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(imagen_gris, cmap='gray')\n",
    "plt.title(f'Imagen en escala de grises\\nshape = {imagen_gris.shape} (tensor 2D)')\n",
    "plt.colorbar(label='Valor del píxel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TENSOR 3D (orden 3) ===\n",
    "imagen_color = np.random.rand(224, 224, 3)   # Imagen RGB\n",
    "\n",
    "print(\"=== TENSOR 3D (orden 3) ===\")\n",
    "print(f\"Imagen a color: shape = {imagen_color.shape}  →  alto × ancho × canales RGB\")\n",
    "print(f\"ndim = {imagen_color.ndim}, total de números = {imagen_color.size:,}\")\n",
    "print()\n",
    "\n",
    "# Visualizar cada canal por separado\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "img_small = np.random.rand(8, 8, 3)  # Versión pequeña para visualizar\n",
    "\n",
    "axes[0].imshow(img_small)\n",
    "axes[0].set_title('Imagen RGB completa')\n",
    "\n",
    "colores = ['Reds', 'Greens', 'Blues']\n",
    "nombres_canal = ['Rojo (R)', 'Verde (G)', 'Azul (B)']\n",
    "for i in range(3):\n",
    "    axes[i+1].imshow(img_small[:, :, i], cmap=colores[i])\n",
    "    axes[i+1].set_title(f'Canal {nombres_canal[i]}\\nshape = (8, 8)')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.suptitle('Tensor 3D: una imagen RGB = 3 matrices apiladas', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TENSOR 4D (orden 4) ===\n",
    "batch_size = 32\n",
    "lote_imagenes = np.random.rand(batch_size, 224, 224, 3)\n",
    "\n",
    "print(\"=== TENSOR 4D (orden 4) ===\")\n",
    "print(f\"Lote de imágenes: shape = {lote_imagenes.shape}\")\n",
    "print(f\"  Dimensión 0: {batch_size} imágenes (batch)\")\n",
    "print(f\"  Dimensión 1: 224 píxeles (alto)\")\n",
    "print(f\"  Dimensión 2: 224 píxeles (ancho)\")\n",
    "print(f\"  Dimensión 3: 3 canales (RGB)\")\n",
    "print(f\"\\nndim = {lote_imagenes.ndim}\")\n",
    "print(f\"Total de números = {lote_imagenes.size:,}\")\n",
    "print(f\"Memoria ≈ {lote_imagenes.nbytes / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de la jerarquía de tensores en ML\n",
    "\n",
    "| Orden | Nombre    | Ejemplo en ML                    |\n",
    "|:-----:|-----------|----------------------------------|\n",
    "| 0     | Escalar   | loss = 0.345                     |\n",
    "| 1     | Vector    | probabilidades = [0.1, 0.7, 0.2] |\n",
    "| 2     | Matriz    | imagen 28×28                     |\n",
    "| 3     | Tensor 3D | imagen RGB 224×224×3             |\n",
    "| 4     | Tensor 4D | batch 32×224×224×3               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. Operaciones tensoriales en Python**\n",
    "\n",
    "En ML, los tensores se manipulan constantemente. Bibliotecas como **NumPy**, **PyTorch** y **TensorFlow** ofrecen herramientas optimizadas para ello. Las operaciones fundamentales son:\n",
    "\n",
    "### 1) Creación de tensores\n",
    "\n",
    "Se pueden crear tensores de ceros, unos, valores aleatorios o a partir de listas existentes, especificando la forma deseada.\n",
    "\n",
    "### 2) Operaciones elemento a elemento\n",
    "\n",
    "Incluyen suma, resta, multiplicación y división entre tensores de igual forma. Cada posición se opera de forma independiente. En redes neuronales esto se usa para aplicar funciones de activación, normalizaciones y otras transformaciones.\n",
    "\n",
    "### 3) Multiplicación matricial (producto punto)\n",
    "\n",
    "Es la **operación fundamental** de las redes neuronales. Cada neurona calcula esencialmente: **salida = pesos · entradas + sesgo**. Esta operación permite combinar información de múltiples variables en una sola salida.\n",
    "\n",
    "### 4) Cambio de forma (reshape)\n",
    "\n",
    "Permite reorganizar los datos **sin modificar su contenido**. Esencial para adaptar tensores a las capas de una red: por ejemplo, convertir una imagen de 28×28 en un vector de 784 elementos.\n",
    "\n",
    "> Reshape cambia la forma del contenedor, no el contenido.\n",
    "\n",
    "### 5) Indexación y slicing\n",
    "\n",
    "Seleccionar partes específicas de un tensor: una imagen dentro de un lote, una región de píxeles o una columna de un dataset. Es crucial para la manipulación de datos y el preprocesamiento.\n",
    "\n",
    "### 6) Reducción de dimensiones (aggregation)\n",
    "\n",
    "Operaciones como suma, promedio, máximo o mínimo permiten condensar información a lo largo de un eje. Se utilizan para calcular métricas, normalizar datos y resumir predicciones.\n",
    "\n",
    "> Consulta el **notebook complementario** para ver cada operación implementada en Python con NumPy.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Creación de tensores\n",
    "\n",
    "ceros     = np.zeros((3, 4))          # Matriz 3×4 de ceros\n",
    "unos      = np.ones((2, 3, 4))        # Tensor 3D de unos\n",
    "aleatorio = np.random.rand(5, 5)      # Matriz 5×5 aleatoria [0, 1)\n",
    "desde_lista = np.array([1, 2, 3])     # Vector desde lista\n",
    "\n",
    "print(\"=== Creación de tensores ===\")\n",
    "print(f\"Ceros:      shape = {ceros.shape}\")\n",
    "print(f\"Unos:       shape = {unos.shape}\")\n",
    "print(f\"Aleatorio:  shape = {aleatorio.shape}\")\n",
    "print(f\"Desde lista: shape = {desde_lista.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Operaciones elemento a elemento\n",
    "\n",
    "A = np.array([1, 2, 3])\n",
    "B = np.array([4, 5, 6])\n",
    "\n",
    "print(\"=== Operaciones elemento a elemento ===\")\n",
    "print(f\"A     = {A}\")\n",
    "print(f\"B     = {B}\")\n",
    "print(f\"A + B = {A + B}   (suma)\")\n",
    "print(f\"A * B = {A * B}  (multiplicación)\")\n",
    "print(f\"A - B = {A - B}\")\n",
    "print(f\"A / B = {A / B}\")\n",
    "print(f\"A ** 2 = {A ** 2}   (potencia)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Multiplicación matricial (producto punto)\n",
    "# La operación FUNDAMENTAL de las redes neuronales\n",
    "\n",
    "X = np.array([[1, 2],     # 2 muestras, 2 características\n",
    "              [3, 4]])\n",
    "\n",
    "W = np.array([[0.5, 0.1],  # Pesos: 2 entradas → 2 salidas\n",
    "              [0.3, 0.8]])\n",
    "\n",
    "Y = np.dot(X, W)   # También: X @ W\n",
    "\n",
    "print(\"=== Multiplicación matricial ===\")\n",
    "print(f\"Entrada X (2×2):\\n{X}\")\n",
    "print(f\"\\nPesos W (2×2):\\n{W}\")\n",
    "print(f\"\\nSalida Y = X · W (2×2):\\n{Y}\")\n",
    "print(f\"\\nVerificación manual:\")\n",
    "print(f\"  Y[0,0] = 1×0.5 + 2×0.3 = {1*0.5 + 2*0.3}\")\n",
    "print(f\"  Y[0,1] = 1×0.1 + 2×0.8 = {1*0.1 + 2*0.8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Cambio de forma (reshape)\n",
    "\n",
    "vector = np.arange(12)  # [0, 1, 2, ..., 11]\n",
    "\n",
    "print(\"=== Reshape ===\")\n",
    "print(f\"Vector original: {vector}\")\n",
    "print(f\"  shape: {vector.shape}\")\n",
    "print()\n",
    "\n",
    "matriz = vector.reshape(3, 4)\n",
    "print(f\"Reshape a (3, 4):\\n{matriz}\")\n",
    "print()\n",
    "\n",
    "tensor_3d = vector.reshape(2, 2, 3)\n",
    "print(f\"Reshape a (2, 2, 3):\")\n",
    "print(tensor_3d)\n",
    "print()\n",
    "print(\"Mismos datos, diferente organización.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Indexación y slicing\n",
    "\n",
    "imagenes = np.random.rand(3, 4, 4)  # 3 imágenes de 4×4\n",
    "\n",
    "print(\"=== Indexación y slicing ===\")\n",
    "print(f\"Tensor de imágenes: shape = {imagenes.shape}\")\n",
    "print()\n",
    "\n",
    "segunda = imagenes[1, :, :]   # Segunda imagen completa\n",
    "print(f\"Segunda imagen (imagenes[1,:,:]): shape = {segunda.shape}\")\n",
    "\n",
    "esquina = imagenes[0, 0:2, 0:2]  # Esquina superior izquierda\n",
    "print(f\"Esquina superior izq (imagenes[0, 0:2, 0:2]): shape = {esquina.shape}\")\n",
    "print(f\"  Valores:\\n{esquina}\")\n",
    "\n",
    "columna = imagenes[:, :, 0]    # Primera columna de todas las imágenes\n",
    "print(f\"\\nPrimera columna de todas (imagenes[:,:,0]): shape = {columna.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Reducción de dimensiones\n",
    "\n",
    "datos = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(\"=== Reducción de dimensiones ===\")\n",
    "print(f\"Datos:\\n{datos}\")\n",
    "print(f\"  shape: {datos.shape}\")\n",
    "print()\n",
    "print(f\"Suma total:            {np.sum(datos)}\")\n",
    "print(f\"Promedio por columna:  {np.mean(datos, axis=0)}   (axis=0: colapsa filas)\")\n",
    "print(f\"Máximo por fila:       {np.max(datos, axis=1)}       (axis=1: colapsa columnas)\")\n",
    "print(f\"Mínimo total:          {np.min(datos)}\")\n",
    "print(f\"Desviación estándar:   {np.std(datos):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11. Ejemplo práctico: red neuronal simple (MNIST)**\n",
    "\n",
    "Veamos cómo los tensores fluyen a través de una red neuronal que clasifica dígitos escritos a mano.\n",
    "\n",
    "### El problema\n",
    "\n",
    "- **Entrada:** imagen de 28 × 28 píxeles en escala de grises (tensor 2D)\n",
    "- **Salida:** probabilidades para 10 clases — dígitos del 0 al 9 (vector)\n",
    "\n",
    "### Arquitectura paso a paso\n",
    "\n",
    "| Paso | Operación | Forma del tensor |\n",
    "|------|-----------|------------------|\n",
    "| 0 | Imagen original | (28, 28) — tensor 2D |\n",
    "| 1 | Aplanar (reshape) | (784,) — vector |\n",
    "| 2 | Capa densa 1: z₁ = x · W₁ + b₁ | (128,) — vector |\n",
    "| 3 | Activación ReLU: a₁ = max(0, z₁) | (128,) — vector |\n",
    "| 4 | Capa densa 2: z₂ = a₁ · W₂ + b₂ | (10,) — vector |\n",
    "| 5 | Softmax: convertir a probabilidades | (10,) — vector de probabilidades |\n",
    "\n",
    "La imagen entra como una matriz de 28×28. Se aplana a un vector de 784 números. Luego pasa por dos capas densas (multiplicaciones matriciales + sesgo), con una activación ReLU intermedia que elimina valores negativos. Finalmente, Softmax convierte los 10 números de salida en probabilidades que suman 1.\n",
    "\n",
    "### Observaciones clave\n",
    "\n",
    "- **Cada capa transforma un tensor en otro tensor** mediante operaciones matemáticas.\n",
    "- Las **multiplicaciones matriciales** son la operación central: combinan información de múltiples variables.\n",
    "- Los **pesos** (W) son matrices que determinan la importancia de cada conexión.\n",
    "- El **sesgo** (b) es un ajuste adicional que permite desplazar la salida.\n",
    "- El resultado final es un **vector de probabilidades** cuya suma siempre es 1.\n",
    "\n",
    "> **Idea fundamental:** Una red neuronal es una *cadena de transformaciones de tensores*.\n",
    "> Aprender significa ajustar los tensores de pesos y sesgos para que estas\n",
    "> transformaciones produzcan la respuesta correcta.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red neuronal paso a paso — una sola imagen\n",
    "\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "\n",
    "# --- Datos de entrada\n",
    "imagen = np.random.rand(28, 28)\n",
    "print(f\"Paso 0 │ Imagen original:    shape = {imagen.shape}  (tensor 2D)\")\n",
    "\n",
    "# --- Paso 1: Aplanar\n",
    "x = imagen.reshape(784)\n",
    "print(f\"Paso 1 │ Aplanar (reshape):  shape = {x.shape}     (vector)\")\n",
    "\n",
    "# --- Paso 2: Capa densa 1 (784 → 128)\n",
    "W1 = np.random.randn(784, 128) * 0.01  # Pesos\n",
    "b1 = np.zeros(128)                      # Sesgo\n",
    "z1 = np.dot(x, W1) + b1\n",
    "print(f\"Paso 2 │ Capa densa 1:       shape = {z1.shape}     (z1 = x·W1 + b1)\")\n",
    "\n",
    "# --- Paso 3: Activación ReLU\n",
    "a1 = np.maximum(0, z1)\n",
    "print(f\"Paso 3 │ ReLU:               shape = {a1.shape}     (elimina negativos)\")\n",
    "print(f\"       │  Valores negativos eliminados: {np.sum(z1 < 0)} de {len(z1)}\")\n",
    "\n",
    "# --- Paso 4: Capa densa 2 (128 → 10)\n",
    "W2 = np.random.randn(128, 10) * 0.01\n",
    "b2 = np.zeros(10)\n",
    "z2 = np.dot(a1, W2) + b2\n",
    "print(f\"Paso 4 │ Capa densa 2:       shape = {z2.shape}       (z2 = a1·W2 + b2)\")\n",
    "\n",
    "# --- Paso 5: Softmax\n",
    "exp_z2 = np.exp(z2 - np.max(z2))  # Estabilidad numérica\n",
    "probabilidades = exp_z2 / np.sum(exp_z2)\n",
    "print(f\"Paso 5 │ Softmax:            shape = {probabilidades.shape}       (probabilidades)\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Predicción: Dígito {np.argmax(probabilidades)}\")\n",
    "print(f\"Confianza:  {np.max(probabilidades)*100:.1f}%\")\n",
    "print(f\"Suma de probabilidades: {np.sum(probabilidades):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las probabilidades de salida\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Imagen de entrada\n",
    "ax1.imshow(imagen, cmap='gray')\n",
    "ax1.set_title(f'Imagen de entrada\\nshape = {imagen.shape}')\n",
    "\n",
    "# Probabilidades de salida\n",
    "colores = ['steelblue'] * 10\n",
    "colores[np.argmax(probabilidades)] = 'tomato'\n",
    "ax2.bar(range(10), probabilidades, color=colores)\n",
    "ax2.set_xlabel('Dígito')\n",
    "ax2.set_ylabel('Probabilidad')\n",
    "ax2.set_title(f'Predicción: Dígito {np.argmax(probabilidades)} ({np.max(probabilidades)*100:.1f}%)')\n",
    "ax2.set_xticks(range(10))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la función ReLU\n",
    "\n",
    "x_vals = np.linspace(-3, 3, 100)\n",
    "relu_vals = np.maximum(0, x_vals)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(x_vals, x_vals, '--', color='gray', alpha=0.5, label='y = x (sin activación)')\n",
    "plt.plot(x_vals, relu_vals, color='steelblue', linewidth=2, label='ReLU: max(0, x)')\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.xlabel('Entrada')\n",
    "plt.ylabel('Salida')\n",
    "plt.title('Función de activación ReLU\\nElimina todos los valores negativos')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **12. Procesando lotes (batches)**\n",
    "\n",
    "En la práctica, una red neuronal casi nunca procesa una sola imagen. Procesa **muchas a la vez**, organizadas en un **lote (batch)**. Esto añade una dimensión adicional al tensor: una imagen tiene forma (28, 28), pero un lote de 32 imágenes tiene forma (32, 28, 28).\n",
    "\n",
    "### ¿Qué ocurre internamente?\n",
    "\n",
    "- Las **32 imágenes** pasan por la **misma transformación** simultáneamente.\n",
    "- El resultado es un tensor (32, 10): 32 vectores de predicción, uno por imagen.\n",
    "- El **sesgo se aplica automáticamente** a cada imagen gracias al *broadcasting* (ajuste automático de dimensiones).\n",
    "- La **GPU procesa todas las imágenes en paralelo**, acelerando enormemente el entrenamiento.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento en lotes\n",
    "\n",
    "np.random.seed(42)\n",
    "batch_size = 32\n",
    "\n",
    "# --- Lote de 32 imágenes\n",
    "lote = np.random.rand(batch_size, 28, 28)\n",
    "print(f\"Lote original:         shape = {lote.shape}   (batch × alto × ancho)\")\n",
    "\n",
    "# --- Aplanar cada imagen\n",
    "lote_flat = lote.reshape(batch_size, 784)\n",
    "print(f\"Lote aplanado:         shape = {lote_flat.shape}  (batch × 784)\")\n",
    "\n",
    "# --- Capa densa 1\n",
    "W1 = np.random.randn(784, 128) * 0.01\n",
    "b1 = np.zeros(128)\n",
    "z1_batch = np.dot(lote_flat, W1) + b1  # Broadcasting automático\n",
    "print(f\"Después de capa 1:     shape = {z1_batch.shape}  (batch × 128)\")\n",
    "\n",
    "# --- ReLU\n",
    "a1_batch = np.maximum(0, z1_batch)\n",
    "print(f\"Después de ReLU:       shape = {a1_batch.shape}  (batch × 128)\")\n",
    "\n",
    "# --- Capa densa 2\n",
    "W2 = np.random.randn(128, 10) * 0.01\n",
    "b2 = np.zeros(10)\n",
    "z2_batch = np.dot(a1_batch, W2) + b2\n",
    "print(f\"Después de capa 2:     shape = {z2_batch.shape}   (batch × 10)\")\n",
    "\n",
    "# --- Softmax por imagen\n",
    "exp_z2 = np.exp(z2_batch - np.max(z2_batch, axis=1, keepdims=True))\n",
    "prob_batch = exp_z2 / np.sum(exp_z2, axis=1, keepdims=True)\n",
    "print(f\"Probabilidades:        shape = {prob_batch.shape}   (batch × 10)\")\n",
    "\n",
    "# --- Predicciones\n",
    "predicciones = np.argmax(prob_batch, axis=1)\n",
    "print(f\"Predicciones:          shape = {predicciones.shape}     (batch,)\")\n",
    "print(f\"\\nPrimeras 10 predicciones: {predicciones[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el flujo de tensores en la red\n",
    "\n",
    "shapes = [\n",
    "    ('Lote imágenes', (32, 28, 28), 'entrada'),\n",
    "    ('Aplanar', (32, 784), 'reshape'),\n",
    "    ('Capa 1', (32, 128), 'capa'),\n",
    "    ('ReLU', (32, 128), 'activación'),\n",
    "    ('Capa 2', (32, 10), 'capa'),\n",
    "    ('Softmax', (32, 10), 'salida'),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 3))\n",
    "\n",
    "colores_tipo = {\n",
    "    'entrada': '#4CAF50',\n",
    "    'reshape': '#FF9800',\n",
    "    'capa': '#2196F3',\n",
    "    'activación': '#9C27B0',\n",
    "    'salida': '#F44336'\n",
    "}\n",
    "\n",
    "for i, (nombre, shape, tipo) in enumerate(shapes):\n",
    "    x_pos = i * 2.2\n",
    "    total = 1\n",
    "    for s in shape:\n",
    "        total *= s\n",
    "    rect = plt.Rectangle((x_pos - 0.8, 0), 1.6, 1, linewidth=2,\n",
    "                         edgecolor=colores_tipo[tipo],\n",
    "                         facecolor=colores_tipo[tipo], alpha=0.3)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x_pos, 0.65, nombre, ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "    ax.text(x_pos, 0.35, str(shape), ha='center', va='center', fontsize=8)\n",
    "\n",
    "    if i < len(shapes) - 1:\n",
    "        ax.annotate('', xy=((i+1)*2.2 - 0.8, 0.5), xytext=(x_pos + 0.8, 0.5),\n",
    "                    arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "\n",
    "ax.set_xlim(-1.5, len(shapes) * 2.2)\n",
    "ax.set_ylim(-0.3, 1.5)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title('Flujo de tensores a través de la red neuronal (batch = 32)', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **13. Frameworks modernos: PyTorch**\n",
    "\n",
    "En la práctica profesional, no implementamos redes neuronales desde cero. Frameworks como **PyTorch** o **TensorFlow** automatizan la gestión de tensores, gradientes y optimización.\n",
    "\n",
    "### ¿Qué hace PyTorch por nosotros?\n",
    "\n",
    "| Tarea | Sin framework | Con PyTorch |\n",
    "|---|---|---|\n",
    "| Gestionar tensores | Manual con NumPy | Automático (tensores con gradientes) |\n",
    "| Calcular gradientes | Implementar backpropagation a mano | Una sola llamada lo hace todo |\n",
    "| Usar GPU | Configuración compleja | Una línea de código |\n",
    "| Optimizar pesos | Escribir el algoritmo de actualización | Una llamada al optimizador |\n",
    "\n",
    "### Idea clave\n",
    "\n",
    "En machine learning moderno, trabajar con redes neuronales es esencialmente **trabajar con tensores de alto orden**: lotes de imágenes (tensor 4D), pesos de capas (tensor 2D) y predicciones (tensor 2D).\n",
    "\n",
    "Los frameworks no eliminan los tensores: los hacen más fáciles de usar. Pero siguen siendo el **núcleo matemático** del sistema.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "\n",
    "    # Definir la red neuronal\n",
    "    class MiRedNeuronal(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MiRedNeuronal, self).__init__()\n",
    "            self.capa1 = nn.Linear(784, 128)   # Capa densa: 784 → 128\n",
    "            self.relu   = nn.ReLU()            # Activación\n",
    "            self.capa2 = nn.Linear(128, 10)    # Capa de salida: 128 → 10\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.capa1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.capa2(x)\n",
    "            return x\n",
    "\n",
    "    # Crear modelo\n",
    "    modelo = MiRedNeuronal()\n",
    "    print(f\"Modelo creado:\\n{modelo}\\n\")\n",
    "\n",
    "    # Simular un lote\n",
    "    lote = torch.randn(32, 784)\n",
    "    print(f\"Entrada:         {lote.shape}\")\n",
    "\n",
    "    # Forward pass\n",
    "    salida = modelo(lote)\n",
    "    print(f\"Salida cruda:    {salida.shape}\")\n",
    "\n",
    "    # Softmax\n",
    "    probabilidades = torch.softmax(salida, dim=1)\n",
    "    print(f\"Probabilidades:  {probabilidades.shape}\")\n",
    "\n",
    "    # Predicciones\n",
    "    predicciones = torch.argmax(probabilidades, dim=1)\n",
    "    print(f\"Predicciones:    {predicciones.shape}\")\n",
    "    print(f\"\\nPrimeras 10: {predicciones[:10].tolist()}\")\n",
    "\n",
    "    # Contar parámetros\n",
    "    total_params = sum(p.numel() for p in modelo.parameters())\n",
    "    print(f\"\\nTotal de parámetros (tensores de pesos y sesgos): {total_params:,}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"PyTorch no está instalado.\")\n",
    "    print(\"Puedes instalarlo con: pip install torch\")\n",
    "    print(\"\\nLa celda anterior con NumPy demuestra los mismos conceptos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PARTE 3 — Tensores en Computación Cuántica**\n",
    "\n",
    "*Donde los tensores no son solo útiles... son indispensables.*\n",
    "\n",
    "La mecánica cuántica se describe matemáticamente con **vectores, matrices y tensores en espacios complejos**. Aquí los tensores no son una conveniencia computacional como en ML: son la estructura fundamental de la teoría.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **14. El mundo cuántico: superposición y entrelazamiento**\n",
    "\n",
    "Antes de hablar de tensores cuánticos, necesitamos entender qué se está modelando.\n",
    "\n",
    "### Bit clásico vs. Qubit\n",
    "\n",
    "| | Bit clásico | Qubit |\n",
    "|---|---|---|\n",
    "| **Estado** | Solo puede valer 0 o 1 | Puede estar en 0 Y 1 al mismo tiempo (superposición) |\n",
    "| **Descripción** | Siempre tiene un estado definido | Su estado se describe con números complejos (amplitudes) |\n",
    "| **Representación** | Un número: 0 o 1 | Un VECTOR de 2 componentes complejas |\n",
    "| **Analogía** | Interruptor (encendido/apagado) | Moneda girando en el aire (aún no ha caído) |\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **15. El estado de un qubit: un vector complejo**\n",
    "\n",
    "Un qubit se representa matemáticamente así:\n",
    "\n",
    "$$\n",
    "|\\psi\\rangle = \\alpha |0\\rangle + \\beta |1\\rangle\n",
    "$$\n",
    "\n",
    "### ¿Qué significa cada símbolo?\n",
    "\n",
    "- $|0\\rangle$ y $|1\\rangle$ son los **estados base**, equivalentes a los vectores $(1,0)$ y $(0,1)$ en 2D.\n",
    "- $\\alpha$ y $\\beta$ son **números complejos** llamados *amplitudes*.\n",
    "- $|\\alpha|^2$ = probabilidad de medir **0**.\n",
    "- $|\\beta|^2$ = probabilidad de medir **1**.\n",
    "- **Restricción de normalización:** $|\\alpha|^2 + |\\beta|^2 = 1$ (las probabilidades deben sumar 1).\n",
    "\n",
    "### Representación como vector columna\n",
    "\n",
    "$$\n",
    "|\\psi\\rangle =\n",
    "\\begin{pmatrix}\n",
    "\\alpha \\\\\n",
    "\\beta\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Los estados base son:\n",
    "\n",
    "$$\n",
    "|0\\rangle =\n",
    "\\begin{pmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{pmatrix}\n",
    "\\qquad\n",
    "|1\\rangle =\n",
    "\\begin{pmatrix}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Ejemplo concreto: superposición equilibrada\n",
    "\n",
    "$$\n",
    "|\\psi\\rangle = \\frac{1}{\\sqrt{2}}|0\\rangle + \\frac{1}{\\sqrt{2}}|1\\rangle\n",
    "= \\frac{1}{\\sqrt{2}}\n",
    "\\begin{pmatrix}\n",
    "1 \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "- Probabilidad de medir 0: $\\left(\\frac{1}{\\sqrt{2}}\\right)^2 = \\frac{1}{2} = 50\\%$\n",
    "- Probabilidad de medir 1: $\\left(\\frac{1}{\\sqrt{2}}\\right)^2 = \\frac{1}{2} = 50\\%$\n",
    "\n",
    "> **Conexión con tensores:** Este vector tiene 2 componentes complejas.\n",
    "> Es un **tensor de orden 1** que vive en un **espacio de Hilbert complejo**\n",
    "> (un espacio vectorial con números complejos y reglas de normalización).\n",
    ">\n",
    "> Un qubit no es un número. Es un **tensor vectorial complejo normalizado**.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Secciones 14 y 15 — Qubits y estados cuánticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estados base de un qubit\n",
    "\n",
    "ket_0 = np.array([1, 0], dtype=complex)  # |0⟩\n",
    "ket_1 = np.array([0, 1], dtype=complex)  # |1⟩\n",
    "\n",
    "print(\"=== ESTADOS BASE DE UN QUBIT ===\")\n",
    "print(f\"|0⟩ = {ket_0}  →  Probabilidad de medir 0: {abs(ket_0[0])**2:.0%}\")\n",
    "print(f\"|1⟩ = {ket_1}  →  Probabilidad de medir 1: {abs(ket_1[1])**2:.0%}\")\n",
    "print(f\"\\nTipo de dato: {ket_0.dtype}\")\n",
    "print(f\"Shape: {ket_0.shape}  →  tensor de orden 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Superposición: el qubit está en |0⟩ Y |1⟩ al mismo tiempo\n",
    "\n",
    "# Superposición equilibrada\n",
    "psi_plus = (1/np.sqrt(2)) * ket_0 + (1/np.sqrt(2)) * ket_1\n",
    "\n",
    "print(\"=== SUPERPOSICIÓN ===\")\n",
    "print(f\"|ψ⟩ = (1/√2)|0⟩ + (1/√2)|1⟩\")\n",
    "print(f\"|ψ⟩ = {psi_plus}\")\n",
    "print()\n",
    "print(f\"Probabilidad de medir |0⟩: |α|² = |{psi_plus[0]:.4f}|² = {abs(psi_plus[0])**2:.4f} = {abs(psi_plus[0])**2:.0%}\")\n",
    "print(f\"Probabilidad de medir |1⟩: |β|² = |{psi_plus[1]:.4f}|² = {abs(psi_plus[1])**2:.4f} = {abs(psi_plus[1])**2:.0%}\")\n",
    "print(f\"\\nSuma de probabilidades: {abs(psi_plus[0])**2 + abs(psi_plus[1])**2:.4f}  (normalizado)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otro estado de superposición (desigual)\n",
    "\n",
    "alpha = np.sqrt(0.8) + 0j  # 80% de probabilidad para |0⟩\n",
    "beta = np.sqrt(0.2) + 0j   # 20% de probabilidad para |1⟩\n",
    "\n",
    "psi_desigual = np.array([alpha, beta])\n",
    "\n",
    "print(\"=== SUPERPOSICIÓN DESIGUAL ===\")\n",
    "print(f\"|ψ⟩ = {alpha:.4f}|0⟩ + {beta:.4f}|1⟩\")\n",
    "print(f\"P(medir 0) = {abs(alpha)**2:.0%}\")\n",
    "print(f\"P(medir 1) = {abs(beta)**2:.0%}\")\n",
    "print(f\"Suma = {abs(alpha)**2 + abs(beta)**2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular mediciones de un qubit\n",
    "\n",
    "def medir_qubit(estado, n_mediciones=1000):\n",
    "    \"\"\"Simula n_mediciones de un qubit.\"\"\"\n",
    "    prob_0 = abs(estado[0])**2\n",
    "    resultados = np.random.choice([0, 1], size=n_mediciones, p=[prob_0, 1-prob_0])\n",
    "    return resultados\n",
    "\n",
    "# Medir el estado en superposición equilibrada\n",
    "resultados = medir_qubit(psi_plus, 10000)\n",
    "\n",
    "print(\"=== SIMULACIÓN DE MEDICIONES ===\")\n",
    "print(f\"Estado: |ψ⟩ = (1/√2)|0⟩ + (1/√2)|1⟩\")\n",
    "print(f\"Mediciones realizadas: 10,000\")\n",
    "print(f\"\\nResultados:\")\n",
    "print(f\"  |0⟩ medido: {np.sum(resultados == 0)} veces ({np.mean(resultados == 0):.1%})\")\n",
    "print(f\"  |1⟩ medido: {np.sum(resultados == 1)} veces ({np.mean(resultados == 1):.1%})\")\n",
    "\n",
    "# Histograma\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(['|0⟩', '|1⟩'], [np.mean(resultados==0), np.mean(resultados==1)], color=['steelblue', 'tomato'])\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Probabilidad teórica (50%)')\n",
    "plt.ylabel('Frecuencia relativa')\n",
    "plt.title('Mediciones de un qubit en superposición equilibrada\\n(10,000 mediciones)')\n",
    "plt.legend()\n",
    "plt.ylim(0, 0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **16. Puertas cuánticas: matrices que transforman qubits**\n",
    "\n",
    "Las **puertas cuánticas** son el equivalente cuántico de las operaciones lógicas. Matemáticamente son **matrices unitarias** que actúan sobre vectores de estado.\n",
    "\n",
    "En lenguaje de tensores: el **estado del qubit** es un tensor de orden 1 (vector), la **puerta cuántica** es un tensor de orden 2 (matriz), y **aplicar una puerta** es realizar una multiplicación matriz × vector.\n",
    "\n",
    "### Puerta X (NOT cuántico)\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Intercambia los estados base: $X|0\\rangle = |1\\rangle$ y $X|1\\rangle = |0\\rangle$.\n",
    "\n",
    "### Puerta Hadamard (H) — la más importante\n",
    "\n",
    "$$\n",
    "H = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Crea **superposición** a partir de un estado puro:\n",
    "\n",
    "$$\n",
    "H|0\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle) \\qquad\n",
    "H|1\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle - |1\\rangle)\n",
    "$$\n",
    "\n",
    "> Es la puerta que convierte un qubit \"decidido\" en uno \"indeciso\".\n",
    "> Fundamental para aprovechar el paralelismo cuántico.\n",
    "\n",
    "### Puerta de fase (S)\n",
    "\n",
    "$$\n",
    "S = \\begin{pmatrix} 1 & 0 \\\\ 0 & i \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Añade una **fase compleja** al estado $|1\\rangle$: $S|1\\rangle = i|1\\rangle$.\n",
    "\n",
    "No cambia las probabilidades de medición, pero sí la **fase**, lo cual afecta interferencias posteriores (la fase es invisible al medir, pero crucial para los cálculos intermedios).\n",
    "\n",
    "### Resumen tensorial\n",
    "\n",
    "Todas estas puertas son **matrices 2×2** (tensores de orden 2) que transforman **vectores de 2 componentes** (tensores de orden 1). La operación es siempre una multiplicación matriz-vector.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las puertas cuánticas básicas\n",
    "\n",
    "# Puerta X (NOT cuántico): intercambia |0⟩ y |1⟩\n",
    "X = np.array([[0, 1],\n",
    "              [1, 0]], dtype=complex)\n",
    "\n",
    "# Puerta Hadamard (H): crea superposición\n",
    "H = (1/np.sqrt(2)) * np.array([[1,  1],\n",
    "                                [1, -1]], dtype=complex)\n",
    "\n",
    "# Puerta de fase (S)\n",
    "S = np.array([[1, 0],\n",
    "              [0, 1j]], dtype=complex)\n",
    "\n",
    "# Puerta Z: cambia la fase de |1⟩\n",
    "Z = np.array([[1,  0],\n",
    "              [0, -1]], dtype=complex)\n",
    "\n",
    "# Identidad\n",
    "I = np.eye(2, dtype=complex)\n",
    "\n",
    "print(\"=== PUERTAS CUÁNTICAS ===\")\n",
    "print(f\"Todas son matrices 2×2 (tensores de orden 2)\\n\")\n",
    "\n",
    "puertas = {'X (NOT)': X, 'H (Hadamard)': H, 'S (Fase)': S, 'Z': Z, 'I (Identidad)': I}\n",
    "for nombre, puerta in puertas.items():\n",
    "    print(f\"{nombre}:\")\n",
    "    print(puerta)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar puertas a qubits\n",
    "\n",
    "print(\"=== PUERTA X (NOT) ===\")\n",
    "print(f\"X|0⟩ = {X @ ket_0}  →  |1⟩\")\n",
    "print(f\"X|1⟩ = {X @ ket_1}  →  |0⟩\")\n",
    "print(\"Intercambia los estados base.\")\n",
    "print()\n",
    "\n",
    "print(\"=== PUERTA HADAMARD ===\")\n",
    "h0 = H @ ket_0\n",
    "h1 = H @ ket_1\n",
    "print(f\"H|0⟩ = {h0}\")\n",
    "print(f\"     = (1/√2)(|0⟩ + |1⟩)  →  superposición equilibrada\")\n",
    "print(f\"     P(0) = {abs(h0[0])**2:.0%}, P(1) = {abs(h0[1])**2:.0%}\")\n",
    "print()\n",
    "print(f\"H|1⟩ = {h1}\")\n",
    "print(f\"     = (1/√2)(|0⟩ - |1⟩)  →  superposición con fase negativa\")\n",
    "print(f\"     P(0) = {abs(h1[0])**2:.0%}, P(1) = {abs(h1[1])**2:.0%}\")\n",
    "print()\n",
    "\n",
    "print(\"=== PUERTA DE FASE (S) ===\")\n",
    "print(f\"S|0⟩ = {S @ ket_0}  →  |0⟩ (sin cambio)\")\n",
    "print(f\"S|1⟩ = {S @ ket_1}  →  i|1⟩ (fase compleja)\")\n",
    "print(\"No cambia las probabilidades, pero sí la fase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propiedad importante: H aplicado dos veces = Identidad\n",
    "\n",
    "print(\"=== PROPIEDAD: H·H = I ===\")\n",
    "print(f\"H·H:\")\n",
    "print(H @ H)\n",
    "print()\n",
    "print(f\"H|0⟩      = {H @ ket_0}\")\n",
    "print(f\"H(H|0⟩)   = {H @ (H @ ket_0)}  →  volvemos a |0⟩\")\n",
    "print()\n",
    "print(\"Aplicar Hadamard dos veces devuelve al estado original.\")\n",
    "print(\"Esto es clave para el algoritmo Deutsch-Jozsa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **17. Múltiples qubits: el producto tensorial**\n",
    "\n",
    "Cuando pasamos de 1 qubit a varios, el espacio de estados crece **exponencialmente**.\n",
    "\n",
    "### Sistema de 2 qubits\n",
    "\n",
    "Los estados base posibles son todas las combinaciones:\n",
    "\n",
    "$$\n",
    "|00\\rangle, \\quad |01\\rangle, \\quad |10\\rangle, \\quad |11\\rangle\n",
    "$$\n",
    "\n",
    "El estado general es una superposición de todos ellos:\n",
    "\n",
    "$$\n",
    "|\\psi\\rangle = \\alpha_{00}|00\\rangle + \\alpha_{01}|01\\rangle + \\alpha_{10}|10\\rangle + \\alpha_{11}|11\\rangle\n",
    "$$\n",
    "\n",
    "Como vector, necesitamos **4 componentes** (porque $2^2 = 4$):\n",
    "\n",
    "$$\n",
    "|\\psi\\rangle =\n",
    "\\begin{pmatrix}\n",
    "\\alpha_{00} \\\\\n",
    "\\alpha_{01} \\\\\n",
    "\\alpha_{10} \\\\\n",
    "\\alpha_{11}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### ¿Cómo combinamos qubits individuales?\n",
    "\n",
    "Usando el **producto tensorial** $\\otimes$. Si tenemos dos qubits separados:\n",
    "\n",
    "$$\n",
    "|\\psi_1\\rangle =\n",
    "\\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}\n",
    "\\qquad\n",
    "|\\psi_2\\rangle =\n",
    "\\begin{pmatrix} \\gamma \\\\ \\delta \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Su producto tensorial combina **todas las posibilidades**:\n",
    "\n",
    "$$\n",
    "|\\psi_1\\rangle \\otimes |\\psi_2\\rangle =\n",
    "\\begin{pmatrix}\n",
    "\\alpha \\cdot \\gamma \\\\\n",
    "\\alpha \\cdot \\delta \\\\\n",
    "\\beta \\cdot \\gamma \\\\\n",
    "\\beta \\cdot \\delta\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Ejemplo concreto\n",
    "\n",
    "$$\n",
    "|0\\rangle \\otimes |1\\rangle =\n",
    "\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n",
    "\\otimes\n",
    "\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n",
    "= |01\\rangle\n",
    "$$\n",
    "\n",
    "### Crecimiento exponencial\n",
    "\n",
    "| Qubits | Componentes del vector de estado | Equivalencia |\n",
    "|--------|----------------------------------|--------------|\n",
    "| 1 | 2 | $2^1$ |\n",
    "| 2 | 4 | $2^2$ |\n",
    "| 3 | 8 | $2^3$ |\n",
    "| 10 | 1,024 | $2^{10}$ |\n",
    "| 20 | 1,048,576 | $2^{20}$ |\n",
    "| 50 | ~$10^{15}$ | Más que la RAM de cualquier supercomputadora |\n",
    "\n",
    "> Cada qubit adicional **duplica** el tamaño del tensor.\n",
    "> Un sistema de 50 qubits requiere un vector con más de un cuatrillón de componentes complejas.\n",
    "> Esta es la razón por la que simular computadoras cuánticas en computadoras clásicas es tan difícil.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Producto tensorial con np.kron (producto de Kronecker)\n",
    "\n",
    "print(\"=== PRODUCTO TENSORIAL ===\")\n",
    "print()\n",
    "\n",
    "# |0⟩ ⊗ |0⟩ = |00⟩\n",
    "ket_00 = np.kron(ket_0, ket_0)\n",
    "print(f\"|0⟩ ⊗ |0⟩ = {ket_00}  →  |00⟩\")\n",
    "\n",
    "# |0⟩ ⊗ |1⟩ = |01⟩\n",
    "ket_01 = np.kron(ket_0, ket_1)\n",
    "print(f\"|0⟩ ⊗ |1⟩ = {ket_01}  →  |01⟩\")\n",
    "\n",
    "# |1⟩ ⊗ |0⟩ = |10⟩\n",
    "ket_10 = np.kron(ket_1, ket_0)\n",
    "print(f\"|1⟩ ⊗ |0⟩ = {ket_10}  →  |10⟩\")\n",
    "\n",
    "# |1⟩ ⊗ |1⟩ = |11⟩\n",
    "ket_11 = np.kron(ket_1, ket_1)\n",
    "print(f\"|1⟩ ⊗ |1⟩ = {ket_11}  →  |11⟩\")\n",
    "\n",
    "print(f\"\\nCada estado base de 2 qubits tiene 4 componentes (2² = 4)\")\n",
    "print(f\"Shape: {ket_00.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Superposición de dos qubits\n",
    "\n",
    "# |+⟩ = (1/√2)(|0⟩ + |1⟩)\n",
    "ket_plus = H @ ket_0\n",
    "\n",
    "# |+⟩ ⊗ |0⟩\n",
    "estado_2q = np.kron(ket_plus, ket_0)\n",
    "\n",
    "print(\"=== SUPERPOSICIÓN DE 2 QUBITS ===\")\n",
    "print(f\"|+⟩ ⊗ |0⟩ = {estado_2q}\")\n",
    "print()\n",
    "print(\"Probabilidades:\")\n",
    "etiquetas = ['|00⟩', '|01⟩', '|10⟩', '|11⟩']\n",
    "for i, (et, amp) in enumerate(zip(etiquetas, estado_2q)):\n",
    "    prob = abs(amp)**2\n",
    "    print(f\"  P({et}) = |{amp:.4f}|² = {prob:.4f} = {prob:.0%}\")\n",
    "print(f\"\\nSuma: {sum(abs(a)**2 for a in estado_2q):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crecimiento exponencial del espacio de estados\n",
    "\n",
    "print(\"=== CRECIMIENTO EXPONENCIAL ===\")\n",
    "print(f\"\\n{'Qubits':>6}  {'Componentes':>12}  {'Memoria (bytes)':>16}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for n in [1, 2, 3, 5, 10, 20, 30, 40, 50]:\n",
    "    componentes = 2**n\n",
    "    memoria = componentes * 16  # 16 bytes por número complejo (complex128)\n",
    "    if memoria < 1e3:\n",
    "        mem_str = f\"{memoria} B\"\n",
    "    elif memoria < 1e6:\n",
    "        mem_str = f\"{memoria/1e3:.1f} KB\"\n",
    "    elif memoria < 1e9:\n",
    "        mem_str = f\"{memoria/1e6:.1f} MB\"\n",
    "    elif memoria < 1e12:\n",
    "        mem_str = f\"{memoria/1e9:.1f} GB\"\n",
    "    elif memoria < 1e15:\n",
    "        mem_str = f\"{memoria/1e12:.1f} TB\"\n",
    "    else:\n",
    "        mem_str = f\"{memoria/1e15:.1f} PB\"\n",
    "    print(f\"{n:>6}  {componentes:>12,}  {mem_str:>16}\")\n",
    "\n",
    "print(\"\\nSimular 50 qubits requiere más memoria que cualquier supercomputadora.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **18. Entrelazamiento cuántico**\n",
    "\n",
    "En sistemas de múltiples qubits, a veces los qubits **no pueden describirse por separado**. Esto se llama **entrelazamiento cuántico**.\n",
    "\n",
    "### Estado separable (NO entrelazado)\n",
    "\n",
    "Si podemos escribir un estado como producto de qubits individuales, es separable:\n",
    "\n",
    "$$\n",
    "|\\psi\\rangle = |0\\rangle \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)\n",
    "$$\n",
    "\n",
    "Cada qubit puede describirse de forma independiente. El tensor del sistema se factoriza.\n",
    "\n",
    "### Estado entrelazado: el par de Bell\n",
    "\n",
    "$$\n",
    "|\\Phi^+\\rangle = \\frac{1}{\\sqrt{2}}(|00\\rangle + |11\\rangle)\n",
    "$$\n",
    "\n",
    "**Pregunta:** ¿Se puede escribir como $|\\psi_1\\rangle \\otimes |\\psi_2\\rangle$?\n",
    "\n",
    "Intentemos:\n",
    "\n",
    "$$\n",
    "(\\alpha|0\\rangle + \\beta|1\\rangle) \\otimes (\\gamma|0\\rangle + \\delta|1\\rangle) = \\alpha\\gamma|00\\rangle + \\alpha\\delta|01\\rangle + \\beta\\gamma|10\\rangle + \\beta\\delta|11\\rangle\n",
    "$$\n",
    "\n",
    "Para igualar con $|\\Phi^+\\rangle$ necesitamos:\n",
    "\n",
    "$$\n",
    "\\alpha\\gamma = \\frac{1}{\\sqrt{2}}, \\quad\n",
    "\\alpha\\delta = 0, \\quad\n",
    "\\beta\\gamma = 0, \\quad\n",
    "\\beta\\delta = \\frac{1}{\\sqrt{2}}\n",
    "$$\n",
    "\n",
    "**Contradicción:** Si $\\alpha\\gamma \\neq 0$, entonces $\\alpha \\neq 0$ y $\\gamma \\neq 0$. Pero $\\alpha\\delta = 0$ con $\\alpha \\neq 0$ implica $\\delta = 0$. Entonces $\\beta\\delta = 0 \\neq \\frac{1}{\\sqrt{2}}$.\n",
    "\n",
    "**No tiene solución.** El estado de Bell es un **tensor irreducible**: no se puede descomponer en partes independientes.\n",
    "\n",
    "### Consecuencia física\n",
    "\n",
    "- Si mides el **primer qubit** y obtienes 0, **automáticamente** sabes que el segundo también es 0.\n",
    "- Esto ocurre **instantáneamente**, sin importar la distancia entre los qubits.\n",
    "- Einstein llamó a esto *\"acción fantasmal a distancia\"* (*spooky action at a distance*).\n",
    "\n",
    "> **Conexión tensorial:** El entrelazamiento es un fenómeno **intrínseco a la estructura tensorial**\n",
    "> de los sistemas cuánticos. Un estado entrelazado es un tensor de orden superior\n",
    "> que no se puede factorizar como producto de tensores de orden inferior.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado separable (NO entrelazado)\n",
    "\n",
    "sep = np.kron(ket_plus, ket_0)  # |+⟩ ⊗ |0⟩\n",
    "\n",
    "print(\"=== ESTADO SEPARABLE ===\")\n",
    "print(f\"|+⟩ ⊗ |0⟩ = (1/√2)(|00⟩ + |10⟩)\")\n",
    "print(f\"Estado: {sep}\")\n",
    "print()\n",
    "print(\"Probabilidades:\")\n",
    "for et, amp in zip(etiquetas, sep):\n",
    "    print(f\"  P({et}) = {abs(amp)**2:.2f}\")\n",
    "print(\"\\nEste estado SE PUEDE factorizar como producto de qubits individuales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado entrelazado: Par de Bell |Φ+⟩ = (1/√2)(|00⟩ + |11⟩)\n",
    "\n",
    "bell = (1/np.sqrt(2)) * (ket_00 + ket_11)\n",
    "\n",
    "print(\"=== ESTADO ENTRELAZADO (PAR DE BELL) ===\")\n",
    "print(f\"|Φ+⟩ = (1/√2)(|00⟩ + |11⟩)\")\n",
    "print(f\"Estado: {bell}\")\n",
    "print()\n",
    "print(\"Probabilidades:\")\n",
    "for et, amp in zip(etiquetas, bell):\n",
    "    print(f\"  P({et}) = {abs(amp)**2:.2f}\")\n",
    "print()\n",
    "print(\"Solo |00⟩ y |11⟩ son posibles.\")\n",
    "print(\"Si mides el primer qubit y obtienes 0, el segundo SIEMPRE será 0.\")\n",
    "print(\"Si mides el primer qubit y obtienes 1, el segundo SIEMPRE será 1.\")\n",
    "print(\"\\nEste estado NO se puede factorizar como producto de qubits individuales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demostración: ¿por qué no se puede factorizar?\n",
    "\n",
    "print(\"=== DEMOSTRACIÓN: BELL NO ES FACTORIZABLE ===\")\n",
    "print()\n",
    "print(\"Si |Φ+⟩ = (α|0⟩+β|1⟩) ⊗ (γ|0⟩+δ|1⟩), entonces:\")\n",
    "print(\"  αγ = 1/√2  (coef. de |00⟩)\")\n",
    "print(\"  αδ = 0      (coef. de |01⟩)\")\n",
    "print(\"  βγ = 0      (coef. de |10⟩)\")\n",
    "print(\"  βδ = 1/√2  (coef. de |11⟩)\")\n",
    "print()\n",
    "print(\"De αγ ≠ 0 → α ≠ 0 y γ ≠ 0\")\n",
    "print(\"De αδ = 0  con α ≠ 0 → δ = 0\")\n",
    "print(\"Pero βδ = 1/√2 requiere δ ≠ 0  ← CONTRADICCIÓN\")\n",
    "print()\n",
    "\n",
    "# Verificación numérica: buscar la mejor factorización\n",
    "print(\"Verificación numérica: intentando factorizar...\")\n",
    "mejor_error = float('inf')\n",
    "for _ in range(10000):\n",
    "    # Generar qubits aleatorios normalizados\n",
    "    a, b = np.random.randn(2) + 1j*np.random.randn(2)\n",
    "    norma = np.sqrt(abs(a)**2 + abs(b)**2)\n",
    "    a, b = a/norma, b/norma\n",
    "\n",
    "    c, d = np.random.randn(2) + 1j*np.random.randn(2)\n",
    "    norma = np.sqrt(abs(c)**2 + abs(d)**2)\n",
    "    c, d = c/norma, d/norma\n",
    "\n",
    "    producto = np.kron(np.array([a, b]), np.array([c, d]))\n",
    "    error = np.linalg.norm(producto - bell)\n",
    "    mejor_error = min(mejor_error, error)\n",
    "\n",
    "print(f\"Mejor aproximación tras 10,000 intentos: error = {mejor_error:.4f}\")\n",
    "print(f\"Error > 0 confirma: NO se puede factorizar. Es un tensor irreducible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular mediciones del par de Bell\n",
    "\n",
    "def medir_2qubits(estado, n_mediciones=10000):\n",
    "    \"\"\"Simula mediciones de un estado de 2 qubits.\"\"\"\n",
    "    probs = np.abs(estado)**2\n",
    "    indices = np.random.choice(4, size=n_mediciones, p=probs)\n",
    "    return indices\n",
    "\n",
    "resultados_bell = medir_2qubits(bell, 10000)\n",
    "\n",
    "print(\"=== MEDICIONES DEL PAR DE BELL ===\")\n",
    "print(f\"Estado: |Φ+⟩ = (1/√2)(|00⟩ + |11⟩)\")\n",
    "print(f\"Mediciones: 10,000\\n\")\n",
    "\n",
    "for i, et in enumerate(etiquetas):\n",
    "    count = np.sum(resultados_bell == i)\n",
    "    print(f\"  {et}: {count:>5} veces  ({count/10000:.1%})\")\n",
    "\n",
    "print(f\"\\nCorrelación perfecta: solo se observan |00⟩ y |11⟩.\")\n",
    "print(f\"Los qubits SIEMPRE coinciden.\")\n",
    "\n",
    "# Visualizar\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Separable\n",
    "res_sep = medir_2qubits(sep, 10000)\n",
    "counts_sep = [np.sum(res_sep == i)/10000 for i in range(4)]\n",
    "ax1.bar(etiquetas, counts_sep, color=['steelblue', 'lightgray', 'steelblue', 'lightgray'])\n",
    "ax1.set_title('Estado SEPARABLE\\n|+⟩ ⊗ |0⟩')\n",
    "ax1.set_ylabel('Frecuencia')\n",
    "ax1.set_ylim(0, 0.7)\n",
    "\n",
    "# Entrelazado\n",
    "counts_bell = [np.sum(resultados_bell == i)/10000 for i in range(4)]\n",
    "ax2.bar(etiquetas, counts_bell, color=['tomato', 'lightgray', 'lightgray', 'tomato'])\n",
    "ax2.set_title('Estado ENTRELAZADO\\n|Φ+⟩ = (1/√2)(|00⟩ + |11⟩)')\n",
    "ax2.set_ylabel('Frecuencia')\n",
    "ax2.set_ylim(0, 0.7)\n",
    "\n",
    "fig.suptitle('Separable vs. Entrelazado: distribución de mediciones', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **19. Puertas en sistemas multi-qubit**\n",
    "\n",
    "### Puerta CNOT (Controlled-NOT)\n",
    "\n",
    "Actúa sobre **2 qubits**: uno de control y uno objetivo. Si el qubit de control es |0⟩, no hace nada al objetivo. Si el qubit de control es |1⟩, aplica NOT al objetivo.\n",
    "\n",
    "**Matriz CNOT** (4×4, porque actúa sobre 2 qubits = 4 estados base):\n",
    "\n",
    "$$\n",
    "\\text{CNOT} =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 1 & 0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "| Entrada | Salida | ¿Qué pasó? |\n",
    "|---------|--------|-----------|\n",
    "| $\\|00\\rangle$ | $\\|00\\rangle$ | Control=0, no cambia nada |\n",
    "| $\\|01\\rangle$ | $\\|01\\rangle$ | Control=0, no cambia nada |\n",
    "| $\\|10\\rangle$ | $\\|11\\rangle$ | Control=1, invierte el objetivo: 0→1 |\n",
    "| $\\|11\\rangle$ | $\\|10\\rangle$ | Control=1, invierte el objetivo: 1→0 |\n",
    "\n",
    "### Creando entrelazamiento con H + CNOT\n",
    "\n",
    "Partiendo del estado inicial |00⟩, se aplica Hadamard al primer qubit para crear superposición: (1/√2)(|00⟩ + |10⟩). Luego se aplica CNOT, que produce el par de Bell: (1/√2)(|00⟩ + |11⟩). Con solo **dos puertas** (dos tensores de orden 2) hemos creado un estado entrelazado a partir de un estado separable.\n",
    "\n",
    "### Estado de múltiples qubits como tensor de orden n\n",
    "\n",
    "Un sistema de 3 qubits tiene un estado:\n",
    "\n",
    "$$\n",
    "|\\psi\\rangle = \\sum_{i,j,k \\in \\{0,1\\}} \\alpha_{ijk} |ijk\\rangle\n",
    "$$\n",
    "\n",
    "Los coeficientes $\\alpha_{ijk}$ forman un **tensor 3D** (un cubo de $2 \\times 2 \\times 2 = 8$ números complejos). Cada índice corresponde a un qubit.\n",
    "\n",
    "> **Analogía con ML:** así como un tensor 3D de imágenes tiene dimensiones alto × ancho × canales,\n",
    "> un tensor cuántico de 3 qubits tiene dimensiones qubit1 × qubit2 × qubit3.\n",
    "\n",
    "### Operaciones tensoriales cuánticas — paralelo con ML\n",
    "\n",
    "| Operación | En ML (NumPy) | En Cuántica |\n",
    "|---|---|---|\n",
    "| Combinar subsistemas | Concatenar arrays | Producto tensorial $\\otimes$ |\n",
    "| Transformar datos | Multiplicación matricial | Multiplicar por puerta cuántica |\n",
    "| Reducir dimensiones | Suma a lo largo de un eje | Traza parcial |\n",
    "| Tipo de números | Reales | Complejos |\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puerta CNOT (Controlled-NOT)\n",
    "\n",
    "CNOT = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 0, 1, 0]\n",
    "], dtype=complex)\n",
    "\n",
    "print(\"=== PUERTA CNOT ===\")\n",
    "print(f\"Matriz CNOT (4×4, tensor de orden 2):\\n{CNOT.real.astype(int)}\")\n",
    "print()\n",
    "print(\"Comportamiento:\")\n",
    "for entrada, nombre_in in [(ket_00, '|00⟩'), (ket_01, '|01⟩'), (ket_10, '|10⟩'), (ket_11, '|11⟩')]:\n",
    "    salida = CNOT @ entrada\n",
    "    # Encontrar cuál estado base es\n",
    "    for i, et in enumerate(etiquetas):\n",
    "        if abs(salida[i]) > 0.9:\n",
    "            nombre_out = et\n",
    "    print(f\"  CNOT{nombre_in} = {nombre_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un par de Bell usando H + CNOT\n",
    "\n",
    "print(\"=== CREANDO UN PAR DE BELL ===\")\n",
    "print()\n",
    "\n",
    "# Paso 1: Estado inicial |00⟩\n",
    "estado = ket_00.copy()\n",
    "print(f\"Paso 1 │ Estado inicial |00⟩:          {estado}\")\n",
    "\n",
    "# Paso 2: Hadamard al primer qubit → H ⊗ I\n",
    "HxI = np.kron(H, I)  # Hadamard en qubit 1, Identidad en qubit 2\n",
    "estado = HxI @ estado\n",
    "print(f\"Paso 2 │ Hadamard al qubit 1 (H⊗I):   {estado}\")\n",
    "print(f\"        │ = (1/√2)(|00⟩ + |10⟩)\")\n",
    "\n",
    "# Paso 3: CNOT\n",
    "estado = CNOT @ estado\n",
    "print(f\"Paso 3 │ CNOT:                         {estado}\")\n",
    "print(f\"        │ = (1/√2)(|00⟩ + |11⟩)  ← PAR DE BELL\")\n",
    "\n",
    "# Verificar\n",
    "print(f\"\\nVerificación:\")\n",
    "print(f\"  ¿Es igual a |Φ+⟩? {np.allclose(estado, bell)}\")\n",
    "print(f\"  Probabilidades: {np.abs(estado)**2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 qubits: tensor con 8 componentes\n",
    "\n",
    "print(\"=== SISTEMA DE 3 QUBITS ===\")\n",
    "print()\n",
    "\n",
    "# Estado |000⟩\n",
    "ket_000 = np.kron(np.kron(ket_0, ket_0), ket_0)\n",
    "print(f\"|000⟩ = {ket_000}\")\n",
    "print(f\"Shape: {ket_000.shape}  →  2³ = 8 componentes\")\n",
    "\n",
    "# Aplicar Hadamard a los 3 qubits → superposición total\n",
    "HxHxH = np.kron(np.kron(H, H), H)\n",
    "superposicion_3q = HxHxH @ ket_000\n",
    "\n",
    "print(f\"\\nAplicar H⊗H⊗H a |000⟩:\")\n",
    "etiquetas_3q = [f'|{i}{j}{k}⟩' for i in '01' for j in '01' for k in '01']\n",
    "for et, amp in zip(etiquetas_3q, superposicion_3q):\n",
    "    print(f\"  {et}: amplitud = {amp.real:+.4f}, P = {abs(amp)**2:.4f}\")\n",
    "\n",
    "print(f\"\\nSuma de probabilidades: {sum(abs(a)**2 for a in superposicion_3q):.4f}\")\n",
    "print(f\"Todos los estados son equiprobables: 1/8 = {1/8:.4f} cada uno.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **20. Ejemplo: algoritmo de Deutsch-Jozsa**\n",
    "\n",
    "Un ejemplo concreto de cómo los tensores cuánticos resuelven un problema más rápido que los métodos clásicos.\n",
    "\n",
    "### El problema\n",
    "\n",
    "Tienes una función $f: \\{0,1\\} \\to \\{0,1\\}$ que puede ser:\n",
    "\n",
    "- **Constante:** siempre devuelve 0, o siempre devuelve 1.\n",
    "- **Balanceada:** devuelve 0 la mitad de las veces y 1 la otra mitad.\n",
    "\n",
    "**Objetivo:** determinar si $f$ es constante o balanceada. Clásicamente se necesitan 2 evaluaciones; cuánticamente basta con 1 sola.\n",
    "\n",
    "### Paso a paso tensorial\n",
    "\n",
    "**Paso 1 — Inicializar:**\n",
    "$$|\\psi_0\\rangle = |0\\rangle = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$$\n",
    "\n",
    "Tensor de orden 1, 2 componentes.\n",
    "\n",
    "**Paso 2 — Hadamard (crear superposición):**\n",
    "$$|\\psi_1\\rangle = H|0\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)$$\n",
    "\n",
    "Ahora el qubit \"explora\" ambos valores simultáneamente.\n",
    "\n",
    "**Paso 3 — Aplicar el oráculo $U_f$:**\n",
    "$U_f$ evalúa $f(0)$ y $f(1)$ **al mismo tiempo** gracias a la superposición. No colapsa el estado, sino que codifica la respuesta en las fases del vector.\n",
    "\n",
    "**Paso 4 — Segunda Hadamard:**\n",
    "$$|\\psi_3\\rangle = H|\\psi_2\\rangle$$\n",
    "\n",
    "La interferencia cuántica hace que las amplitudes se sumen o cancelen:\n",
    "- Si $f$ es constante → las amplitudes se refuerzan hacia $|0\\rangle$.\n",
    "- Si $f$ es balanceada → las amplitudes se refuerzan hacia $|1\\rangle$.\n",
    "\n",
    "**Paso 5 — Medición:**\n",
    "$$\n",
    "\\text{Si medimos } |0\\rangle \\Rightarrow f \\text{ es constante} \\qquad\n",
    "\\text{Si medimos } |1\\rangle \\Rightarrow f \\text{ es balanceada}\n",
    "$$\n",
    "\n",
    "Una **sola medición** basta, porque las transformaciones tensoriales (Hadamard, oráculo, Hadamard) dirigieron el estado hacia la respuesta correcta.\n",
    "\n",
    "### Conexión tensorial\n",
    "\n",
    "- Cada paso es una **multiplicación de un tensor de orden 2 (puerta) por un tensor de orden 1 (estado)**.\n",
    "- La superposición permite operar sobre todos los valores de entrada al mismo tiempo.\n",
    "- La interferencia (constructiva o destructiva) es consecuencia directa de las **propiedades lineales de los tensores**: sumar y restar componentes complejas.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica: Sección 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo de Deutsch-Jozsa (versión simplificada de 1 qubit)\n",
    "\n",
    "def deutsch_jozsa(f_tipo):\n",
    "    \"\"\"\n",
    "    Simula el algoritmo de Deutsch-Jozsa.\n",
    "    f_tipo: 'constante_0', 'constante_1', 'balanceada_id', 'balanceada_not'\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Función: {f_tipo}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Definir el oráculo Uf como una matriz 2×2\n",
    "    if f_tipo == 'constante_0':      # f(x) = 0 para todo x\n",
    "        Uf = I.copy()                # No hace nada (fase = 0)\n",
    "    elif f_tipo == 'constante_1':    # f(x) = 1 para todo x\n",
    "        Uf = -I.copy()               # Fase global -1\n",
    "    elif f_tipo == 'balanceada_id':  # f(x) = x\n",
    "        Uf = Z.copy()                # Cambia fase de |1⟩\n",
    "    elif f_tipo == 'balanceada_not': # f(x) = NOT(x)\n",
    "        Uf = -Z.copy()               # Cambia fase de |0⟩\n",
    "\n",
    "    # Paso 1: Inicializar |0⟩\n",
    "    psi = ket_0.copy()\n",
    "    print(f\"Paso 1 │ |ψ₀⟩ = {psi}\")\n",
    "\n",
    "    # Paso 2: Hadamard → superposición\n",
    "    psi = H @ psi\n",
    "    print(f\"Paso 2 │ H|ψ₀⟩ = {psi}  (superposición)\")\n",
    "\n",
    "    # Paso 3: Aplicar oráculo\n",
    "    psi = Uf @ psi\n",
    "    print(f\"Paso 3 │ Uf·|ψ₁⟩ = {psi}  (oráculo aplicado)\")\n",
    "\n",
    "    # Paso 4: Hadamard de nuevo → interferencia\n",
    "    psi = H @ psi\n",
    "    print(f\"Paso 4 │ H·|ψ₂⟩ = {psi}  (interferencia)\")\n",
    "\n",
    "    # Paso 5: Medir\n",
    "    prob_0 = abs(psi[0])**2\n",
    "    prob_1 = abs(psi[1])**2\n",
    "    resultado = 0 if prob_0 > 0.5 else 1\n",
    "    tipo = \"CONSTANTE\" if resultado == 0 else \"BALANCEADA\"\n",
    "\n",
    "    print(f\"Paso 5 │ P(|0⟩) = {prob_0:.4f}, P(|1⟩) = {prob_1:.4f}\")\n",
    "    print(f\"       │ Medimos: |{resultado}⟩ → f es {tipo}\")\n",
    "\n",
    "    return tipo\n",
    "\n",
    "# Probar con las 4 funciones posibles\n",
    "for f in ['constante_0', 'constante_1', 'balanceada_id', 'balanceada_not']:\n",
    "    deutsch_jozsa(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deutsch-Jozsa: clásico vs cuántico\n",
    "\n",
    "| | Clásico | Cuántico |\n",
    "|---|---|---|\n",
    "| **Paso 1** | Evaluar f(0) → un resultado | Hadamard → superposición |\n",
    "| **Paso 2** | Evaluar f(1) → otro resultado | 1 evaluación de f (sobre la superposición) |\n",
    "| **Paso 3** | Comparar ambos resultados | Hadamard → interferencia |\n",
    "| **Resultado** | 2 evaluaciones necesarias | 1 sola evaluación basta |\n",
    "\n",
    "> **Ventaja cuántica:** el producto tensorial permite evaluar f(0) y f(1)\n",
    "> **simultáneamente** gracias a la superposición."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusión**\n",
    "\n",
    "1. Los **tensores** son herramientas universales para representar relaciones entre direcciones, dimensiones o subsistemas.\n",
    "\n",
    "2. En **física**, siguen reglas de transformación estrictas y describen magnitudes que existen independientemente del observador.\n",
    "\n",
    "3. En **machine learning**, son contenedores multidimensionales que permiten operaciones masivas en paralelo, impulsando el entrenamiento de redes neuronales.\n",
    "\n",
    "4. En **computación cuántica**, los tensores son la estructura fundamental: los estados son vectores complejos, las operaciones son matrices unitarias, y el entrelazamiento es la manifestación de tensores irreducibles.\n",
    "\n",
    "5. La **dimensión y el orden** indican la complejidad de las relaciones: mientras más alto el orden, más rica la estructura que el tensor puede capturar.\n",
    "\n",
    "> El hilo conductor es siempre el mismo: **organizar información multidimensional\n",
    "> de forma estructurada y transformarla según reglas matemáticas precisas**.\n",
    "> Eso es, en esencia, lo que hace un tensor.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mapa comparativo: tensores en tres mundos**\n",
    "\n",
    "| Aspecto | Física/Geometría | Machine Learning | Computación Cuántica |\n",
    "|---|---|---|---|\n",
    "| **¿Qué es un tensor?** | Objeto geométrico invariante | Array multidimensional eficiente | Vector/operador en espacio complejo |\n",
    "| **Tipo de números** | Reales | Reales (o float32/64) | Complejos |\n",
    "| **Orden 0** | Temperatura, masa | Loss, accuracy | — |\n",
    "| **Orden 1** | Velocidad, fuerza | Características, embeddings | Estado de 1 qubit |\n",
    "| **Orden 2** | Tensor de esfuerzos | Pesos de una capa, imagen B/N | Puerta cuántica de 1 qubit |\n",
    "| **Orden 3+** | Elasticidad, piezoelectricidad | Lotes de imágenes RGB | Estado de n qubits |\n",
    "| **Operación central** | Transformación de coordenadas | Producto matricial + sesgo | Producto tensorial + puertas |\n",
    "| **¿Reglas de transformación?** | Sí (esenciales) | No necesariamente | Sí (unitariedad) |\n",
    "| **Crecimiento** | $n^r$ ($n$=dims, $r$=orden) | Arbitrario | $2^n$ (exponencial en qubits) |\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización final: resumen de todos los conceptos\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# --- Física: tensor de esfuerzos rotado\n",
    "ax = axes[0]\n",
    "angulos = np.linspace(0, 360, 100)\n",
    "sigma = np.array([[100, 20], [20, 50]])\n",
    "trazas = []\n",
    "comp_00 = []\n",
    "for ang in angulos:\n",
    "    rad = np.radians(ang)\n",
    "    R = np.array([[np.cos(rad), -np.sin(rad)],\n",
    "                  [np.sin(rad),  np.cos(rad)]])\n",
    "    sigma_rot = R @ sigma @ R.T\n",
    "    trazas.append(np.trace(sigma_rot))\n",
    "    comp_00.append(sigma_rot[0, 0])\n",
    "ax.plot(angulos, comp_00, 'b-', label='σ₁₁ (componente)', alpha=0.7)\n",
    "ax.plot(angulos, trazas, 'r--', linewidth=2, label='Traza (invariante)')\n",
    "ax.set_xlabel('Ángulo de rotación (°)')\n",
    "ax.set_ylabel('Valor')\n",
    "ax.set_title('Física: Componentes vs Invariantes')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- ML: shapes a través de la red\n",
    "ax = axes[1]\n",
    "capas = ['Imagen\\n28×28', 'Flat\\n784', 'Densa1\\n128', 'ReLU\\n128', 'Densa2\\n10', 'Softmax\\n10']\n",
    "sizes = [784, 784, 128, 128, 10, 10]\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(capas)))\n",
    "ax.bar(range(len(capas)), sizes, color=colors, edgecolor='black', alpha=0.8)\n",
    "ax.set_xticks(range(len(capas)))\n",
    "ax.set_xticklabels(capas, fontsize=8)\n",
    "ax.set_ylabel('Dimensiones del tensor')\n",
    "ax.set_title('ML: Flujo de tensores en red MNIST')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# --- Cuántica: crecimiento exponencial\n",
    "ax = axes[2]\n",
    "n_qubits = np.arange(1, 21)\n",
    "componentes = 2 ** n_qubits\n",
    "ax.semilogy(n_qubits, componentes, 'go-', markersize=5, linewidth=2)\n",
    "ax.fill_between(n_qubits, componentes, alpha=0.1, color='green')\n",
    "ax.set_xlabel('Número de qubits')\n",
    "ax.set_ylabel('Componentes del tensor')\n",
    "ax.set_title('Cuántica: Crecimiento exponencial')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=1e6, color='red', linestyle='--', alpha=0.5, label='1 millón')\n",
    "ax.legend()\n",
    "\n",
    "plt.suptitle('Tensores en tres mundos', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Glosario rápido**\n",
    "\n",
    "| Término | Definición |\n",
    "|---|---|\n",
    "| **Tensor** | Objeto matemático que generaliza escalares, vectores y matrices a cualquier número de dimensiones |\n",
    "| **Orden (rango)** | Número de índices necesarios para especificar un componente del tensor |\n",
    "| **Componentes** | Los números que representan al tensor en un sistema de coordenadas particular |\n",
    "| **Invariante** | Propiedad del tensor que no cambia al cambiar el sistema de referencia |\n",
    "| **Producto tensorial** ($\\otimes$) | Operación que combina dos tensores en uno de orden superior |\n",
    "| **Escalar** | Tensor de orden 0 (un solo número) |\n",
    "| **Vector** | Tensor de orden 1 (magnitud y dirección) |\n",
    "| **Batch** | Lote de datos procesados simultáneamente por una red neuronal |\n",
    "| **Reshape** | Reorganizar las dimensiones de un tensor sin cambiar sus datos |\n",
    "| **Broadcasting** | Ajuste automático de dimensiones para operar tensores de formas compatibles |\n",
    "| **Qubit** | Unidad básica de información cuántica; tensor de orden 1 con 2 componentes complejas |\n",
    "| **Superposición** | Estado cuántico que combina múltiples estados base simultáneamente |\n",
    "| **Entrelazamiento** | Correlación cuántica donde el tensor del sistema no puede factorizarse |\n",
    "| **Puerta cuántica** | Matriz unitaria que transforma el estado de uno o más qubits |\n",
    "| **Espacio de Hilbert** | Espacio vectorial complejo donde viven los estados cuánticos |\n",
    "| **ReLU** | Función de activación: $\\max(0, x)$; elimina valores negativos |\n",
    "| **Softmax** | Función que convierte un vector de números en probabilidades que suman 1 |\n",
    "| **Backpropagation** | Algoritmo para calcular gradientes y ajustar los pesos de una red neuronal |\n",
    "\n",
    "---\n",
    "\n",
    "*Gracias por acompañarme en este viaje desde los escalares hasta los qubits entrelazados.*"
   ]
  }
 ]
}